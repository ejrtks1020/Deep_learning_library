{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_3.1 케라스 보스턴 주택 가격 모델.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ejrtks1020/Deep_learning_library/blob/main/_3_1_%EC%BC%80%EB%9D%BC%EC%8A%A4_%EB%B3%B4%EC%8A%A4%ED%84%B4_%EC%A3%BC%ED%83%9D_%EA%B0%80%EA%B2%A9_%EB%AA%A8%EB%8D%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj-RA7rQLSC4"
      },
      "source": [
        "# 케라스 보스턴 주택 가격 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1rSC60ILf0U"
      },
      "source": [
        "### modules import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmYcVLNsmFR_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbRqQY1aMMTU"
      },
      "source": [
        "### 데이터 로드\n",
        "- 데이터의 수가 상당히 적기 때문에 테스트 데이터의 비율을 20%로 지정\n",
        "\n",
        "- 13개의 특성을 가짐\n",
        "\n",
        "- 각각의 특성이 모두 다른 스케일, 즉 단위가 모두 다름\n",
        "  - 범죄율: 0~1 사이의 값\n",
        "  - 방의 개수 3~9 사이의 값\n",
        "\n",
        "- 정답 레이블은 주택 가격의 중간가격($1000 단위)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWHBrPVTMGyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb78d68f-000a-433e-afdc-934888bc619d"
      },
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full , y_train_full),  (x_test, y_test) = load_data(path = 'boston_housing.npz',\n",
        "                                                             test_split = 0.2,\n",
        "                                                             seed = 111)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCTcnMT6Mgx9"
      },
      "source": [
        "### 데이터 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdisxCBbMbRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c5fadd-18c2-43c1-a138-87509a6d24af"
      },
      "source": [
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train_full.shape, y_train_full.shape))\n",
        "print('테스트 데이터: {}\\t레이블: {}'.format(x_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjEoDJ6fM4I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "114742b7-d872-46f3-f9ea-0d0eb03bff72"
      },
      "source": [
        "print(x_train_full[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.8750e-02 2.8000e+01 1.5040e+01 0.0000e+00 4.6400e-01 6.2110e+00\n",
            " 2.8900e+01 3.6659e+00 4.0000e+00 2.7000e+02 1.8200e+01 3.9633e+02\n",
            " 6.2100e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-V0pQdbNSso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315b9c02-ccb1-4085-b443-414e34e69de8"
      },
      "source": [
        "print(y_train_full[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ZK_dJdOlCu"
      },
      "source": [
        "### 데이터 전처리\n",
        "- Standardization\n",
        "\n",
        "- 특성의 단위가 모두 다르기 때문에 **동일한 범위로 조정**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjRcDM_CNV--"
      },
      "source": [
        "mean = np.mean(x_train_full, axis = 0)\n",
        "std = np.std(x_train_full, axis = 0)\n",
        "\n",
        "x_train_preprocessed = (x_train_full - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_preprocessed, y_train_full, \n",
        "                                                  test_size = 0.3,\n",
        "                                                  random_state = 111)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1fl37t9PR0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0919696-a8b7-4b80-819f-aeb296617354"
      },
      "source": [
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train_full.shape, y_train_full.shape))\n",
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train.shape, y_train.shape))\n",
        "print('검증 데이터: {}\\t레이블: {}'.format(x_val.shape, y_val.shape))\n",
        "print('테스트 데이터: {}\\t레이블: {}'.format(x_test.shape, y_test.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "학습 데이터: (282, 13)\t레이블: (282,)\n",
            "검증 데이터: (122, 13)\t레이블: (122,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTcwvMqdPynu"
      },
      "source": [
        "### 모델 구성\n",
        "- 학습 데이터가 매우 적은 경우에 모델의 깊이를 깊게 할수록  \n",
        "  과대적합(Overfitting)이 일어날 확률이 높음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P7pAnqUPcCf"
      },
      "source": [
        "model = Sequential([Dense(100 , activation = 'relu', input_shape = (13, ), name = 'dense1'),\n",
        "                    Dense(64 ,activation='relu', name = 'dense2'),\n",
        "                    Dense(32, activation='relu', name = 'dense3'),\n",
        "                    Dense(1 , name = 'output')])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRi6Vd8WQYyj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3832894a-9091-485e-dd01-4f2645c5c613"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense1 (Dense)               (None, 100)               1400      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 64)                6464      \n",
            "_________________________________________________________________\n",
            "dense3 (Dense)               (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 9,977\n",
            "Trainable params: 9,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-dFvQRGQalM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "00272a63-f561-4eca-d24d-71aaa9aa4ff6"
      },
      "source": [
        "plot_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m05yRQmQmFA"
      },
      "source": [
        "### 모델 컴파일(compile)\n",
        "\n",
        "- 회귀 문제에서는 주로 평균제곱오차(MSE, Mean Squared Error)를 손실함수로,  \n",
        "  평균절대오차(MAE, Mean Absolute Error)를 평가지표로 많이 사용!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z2IMfH3QkGv"
      },
      "source": [
        "model.compile(loss = 'mse',\n",
        "              optimizer = Adam(learning_rate=1e-2),\n",
        "              metrics =['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YhN4fzmRQpY"
      },
      "source": [
        "### 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGA9gPIERPxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a4a946-7f50-4115-9d65-d251f47421cb"
      },
      "source": [
        "history = model.fit(x_train, y_train, epochs=300,\n",
        "                    validation_data = (x_val ,y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 23ms/step - loss: 285.1888 - mae: 14.0729 - val_loss: 132.4612 - val_mae: 9.1090\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 60.9891 - mae: 5.9218 - val_loss: 31.4368 - val_mae: 4.4589\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 33.7114 - mae: 4.2293 - val_loss: 22.2753 - val_mae: 3.6017\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 21.5946 - mae: 3.4391 - val_loss: 13.9826 - val_mae: 2.9190\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 16.3538 - mae: 2.8935 - val_loss: 11.7222 - val_mae: 2.7147\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.6432 - mae: 2.5889 - val_loss: 10.9746 - val_mae: 2.5883\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 12.6475 - mae: 2.4426 - val_loss: 9.1843 - val_mae: 2.3985\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.5112 - mae: 2.5104 - val_loss: 9.8296 - val_mae: 2.4060\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.3260 - mae: 2.3506 - val_loss: 8.1732 - val_mae: 2.2383\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.1601 - mae: 2.3899 - val_loss: 8.3317 - val_mae: 2.2944\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 11.3497 - mae: 2.3828 - val_loss: 9.6377 - val_mae: 2.3146\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4039 - mae: 2.3526 - val_loss: 8.3838 - val_mae: 2.3106\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6115 - mae: 2.1968 - val_loss: 8.4295 - val_mae: 2.2763\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.5119 - mae: 2.1870 - val_loss: 9.0308 - val_mae: 2.4176\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5966 - mae: 2.0715 - val_loss: 8.1153 - val_mae: 2.2021\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6300 - mae: 2.1294 - val_loss: 8.3422 - val_mae: 2.2117\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.7119 - mae: 2.1223 - val_loss: 10.9265 - val_mae: 2.6191\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6290 - mae: 2.3363 - val_loss: 8.8320 - val_mae: 2.3394\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.1268 - mae: 2.0547 - val_loss: 7.6580 - val_mae: 2.1378\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1541 - mae: 1.8875 - val_loss: 9.4982 - val_mae: 2.3932\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6636 - mae: 2.0445 - val_loss: 7.8261 - val_mae: 2.1954\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.2969 - mae: 1.9602 - val_loss: 9.3016 - val_mae: 2.4027\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.6526 - mae: 2.0690 - val_loss: 8.9616 - val_mae: 2.2930\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.1071 - mae: 1.9766 - val_loss: 9.3342 - val_mae: 2.4466\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.2435 - mae: 1.9778 - val_loss: 8.0338 - val_mae: 2.1472\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.0203 - mae: 1.9266 - val_loss: 9.5022 - val_mae: 2.4783\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7252 - mae: 2.0077 - val_loss: 8.8931 - val_mae: 2.2959\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0066 - mae: 1.8350 - val_loss: 8.3985 - val_mae: 2.3100\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2855 - mae: 1.7324 - val_loss: 7.6339 - val_mae: 2.1396\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.7132 - mae: 1.6676 - val_loss: 8.6414 - val_mae: 2.2191\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3748 - mae: 1.5641 - val_loss: 8.7213 - val_mae: 2.2402\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1378 - mae: 1.5473 - val_loss: 8.9902 - val_mae: 2.2870\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2271 - mae: 1.5613 - val_loss: 8.4335 - val_mae: 2.2162\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9779 - mae: 1.4863 - val_loss: 7.7699 - val_mae: 2.1254\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3143 - mae: 1.5621 - val_loss: 8.6094 - val_mae: 2.2999\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7895 - mae: 1.4665 - val_loss: 8.9148 - val_mae: 2.2828\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5302 - mae: 1.4156 - val_loss: 7.5051 - val_mae: 2.1348\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5357 - mae: 1.4503 - val_loss: 10.5374 - val_mae: 2.4405\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1149 - mae: 1.5448 - val_loss: 7.9815 - val_mae: 2.1960\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8561 - mae: 1.5002 - val_loss: 8.3472 - val_mae: 2.1856\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2951 - mae: 1.6390 - val_loss: 12.8807 - val_mae: 2.5689\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.1990 - mae: 1.9864 - val_loss: 12.5896 - val_mae: 2.6215\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9256 - mae: 1.9454 - val_loss: 11.4258 - val_mae: 2.3497\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8106 - mae: 1.8832 - val_loss: 10.2964 - val_mae: 2.4322\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4844 - mae: 1.8608 - val_loss: 9.8603 - val_mae: 2.5417\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4697 - mae: 1.8225 - val_loss: 9.2892 - val_mae: 2.3529\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.2913 - mae: 1.6660 - val_loss: 9.3370 - val_mae: 2.1848\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0311 - mae: 1.7460 - val_loss: 9.5731 - val_mae: 2.2619\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8647 - mae: 1.4384 - val_loss: 8.6994 - val_mae: 2.2281\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3809 - mae: 1.4054 - val_loss: 9.4356 - val_mae: 2.3151\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0862 - mae: 1.3129 - val_loss: 9.1816 - val_mae: 2.2279\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3085 - mae: 1.3746 - val_loss: 11.2422 - val_mae: 2.4667\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.9356 - mae: 1.3286 - val_loss: 8.2461 - val_mae: 2.1783\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8175 - mae: 1.2611 - val_loss: 10.0385 - val_mae: 2.3499\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7857 - mae: 1.2352 - val_loss: 9.4736 - val_mae: 2.3217\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7775 - mae: 1.2551 - val_loss: 9.3844 - val_mae: 2.3087\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9234 - mae: 1.3067 - val_loss: 11.1539 - val_mae: 2.3834\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0753 - mae: 1.3376 - val_loss: 9.2300 - val_mae: 2.2774\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1057 - mae: 1.3423 - val_loss: 9.5917 - val_mae: 2.2864\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6852 - mae: 1.2283 - val_loss: 8.9053 - val_mae: 2.3544\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5856 - mae: 1.2056 - val_loss: 9.4798 - val_mae: 2.3067\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4193 - mae: 1.1479 - val_loss: 9.8255 - val_mae: 2.2832\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5063 - mae: 1.1805 - val_loss: 11.1340 - val_mae: 2.3616\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6236 - mae: 1.2079 - val_loss: 9.7708 - val_mae: 2.3018\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4662 - mae: 1.1970 - val_loss: 9.5195 - val_mae: 2.3871\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.7861 - mae: 1.2607 - val_loss: 9.4123 - val_mae: 2.3852\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6312 - mae: 1.4687 - val_loss: 9.2010 - val_mae: 2.3053\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.1183 - mae: 1.3503 - val_loss: 9.6328 - val_mae: 2.3189\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6874 - mae: 1.1910 - val_loss: 9.9228 - val_mae: 2.3417\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4547 - mae: 1.1567 - val_loss: 9.7423 - val_mae: 2.3327\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6016 - mae: 1.1908 - val_loss: 9.4184 - val_mae: 2.2883\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8750 - mae: 1.2913 - val_loss: 13.7638 - val_mae: 2.7948\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5214 - mae: 1.4178 - val_loss: 10.2682 - val_mae: 2.4105\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6438 - mae: 1.2447 - val_loss: 10.1312 - val_mae: 2.3531\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2133 - mae: 1.1140 - val_loss: 10.3046 - val_mae: 2.3407\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1814 - mae: 1.1072 - val_loss: 10.1794 - val_mae: 2.4556\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2946 - mae: 1.1485 - val_loss: 11.1768 - val_mae: 2.5410\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5618 - mae: 1.2212 - val_loss: 11.6183 - val_mae: 2.4807\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6685 - mae: 1.2216 - val_loss: 8.6998 - val_mae: 2.2512\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1158 - mae: 1.3771 - val_loss: 15.6394 - val_mae: 2.8481\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.1748 - mae: 1.6848 - val_loss: 8.8007 - val_mae: 2.2381\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.0459 - mae: 1.6951 - val_loss: 19.2002 - val_mae: 2.9916\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4059 - mae: 2.0203 - val_loss: 10.7390 - val_mae: 2.4885\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8611 - mae: 1.5211 - val_loss: 11.0370 - val_mae: 2.3804\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1439 - mae: 1.3618 - val_loss: 10.7174 - val_mae: 2.6039\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6026 - mae: 1.4084 - val_loss: 11.0351 - val_mae: 2.4506\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7187 - mae: 1.2811 - val_loss: 14.0560 - val_mae: 2.6463\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6602 - mae: 1.2666 - val_loss: 10.2902 - val_mae: 2.3590\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4854 - mae: 1.1738 - val_loss: 9.8214 - val_mae: 2.2780\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8967 - mae: 1.2007 - val_loss: 11.2804 - val_mae: 2.5779\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.0052 - mae: 1.3146 - val_loss: 9.3233 - val_mae: 2.2071\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.3725 - mae: 1.1770 - val_loss: 8.8493 - val_mae: 2.3151\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.6330 - mae: 1.2088 - val_loss: 13.4340 - val_mae: 2.6950\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9080 - mae: 1.2733 - val_loss: 8.9968 - val_mae: 2.2020\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5845 - mae: 1.2295 - val_loss: 11.0082 - val_mae: 2.4073\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3258 - mae: 1.1711 - val_loss: 10.3363 - val_mae: 2.4280\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.2516 - mae: 1.1889 - val_loss: 9.2513 - val_mae: 2.3464\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6619 - mae: 1.2131 - val_loss: 11.4939 - val_mae: 2.5430\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4830 - mae: 1.3806 - val_loss: 9.0067 - val_mae: 2.2798\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.4701 - mae: 1.2325 - val_loss: 12.5664 - val_mae: 2.6831\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5988 - mae: 1.2395 - val_loss: 9.7798 - val_mae: 2.3831\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.2343 - mae: 1.1198 - val_loss: 9.0341 - val_mae: 2.3580\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5550 - mae: 1.2141 - val_loss: 14.2053 - val_mae: 2.6952\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5645 - mae: 1.2056 - val_loss: 9.8426 - val_mae: 2.2942\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5789 - mae: 1.1535 - val_loss: 10.2338 - val_mae: 2.3885\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5425 - mae: 1.2156 - val_loss: 13.1736 - val_mae: 2.7916\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.2376 - mae: 1.4192 - val_loss: 9.4958 - val_mae: 2.3423\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1641 - mae: 1.0723 - val_loss: 8.6834 - val_mae: 2.2009\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8632 - mae: 1.0007 - val_loss: 9.2758 - val_mae: 2.2323\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4588 - mae: 0.8906 - val_loss: 9.1351 - val_mae: 2.2581\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4608 - mae: 0.8761 - val_loss: 9.0219 - val_mae: 2.2472\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4857 - mae: 0.8737 - val_loss: 9.1903 - val_mae: 2.2834\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4119 - mae: 0.8857 - val_loss: 10.2050 - val_mae: 2.3036\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.7406 - mae: 1.0108 - val_loss: 9.2633 - val_mae: 2.2800\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5226 - mae: 0.9062 - val_loss: 8.1376 - val_mae: 2.2115\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0069 - mae: 1.0567 - val_loss: 10.3821 - val_mae: 2.4309\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7054 - mae: 0.9596 - val_loss: 10.8108 - val_mae: 2.3494\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5294 - mae: 0.9440 - val_loss: 9.7238 - val_mae: 2.2460\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6270 - mae: 0.9532 - val_loss: 11.4559 - val_mae: 2.5892\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0756 - mae: 1.0644 - val_loss: 9.1897 - val_mae: 2.3558\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5890 - mae: 0.9498 - val_loss: 10.1614 - val_mae: 2.3077\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6721 - mae: 0.9743 - val_loss: 11.4381 - val_mae: 2.4922\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2118 - mae: 1.0703 - val_loss: 12.0315 - val_mae: 2.6364\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8629 - mae: 1.0530 - val_loss: 8.8527 - val_mae: 2.2178\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4034 - mae: 0.8576 - val_loss: 11.2876 - val_mae: 2.4354\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3612 - mae: 0.8502 - val_loss: 8.8945 - val_mae: 2.2459\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3092 - mae: 0.8556 - val_loss: 10.4297 - val_mae: 2.3106\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1607 - mae: 0.7883 - val_loss: 9.5958 - val_mae: 2.2816\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2351 - mae: 0.7899 - val_loss: 9.6361 - val_mae: 2.3442\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.7324 - mae: 0.9964 - val_loss: 9.4002 - val_mae: 2.2995\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7885 - mae: 0.9882 - val_loss: 11.8277 - val_mae: 2.4780\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4709 - mae: 0.9136 - val_loss: 10.2937 - val_mae: 2.3377\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5925 - mae: 0.9474 - val_loss: 10.6278 - val_mae: 2.3984\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3362 - mae: 0.8596 - val_loss: 8.3861 - val_mae: 2.1852\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2758 - mae: 0.8256 - val_loss: 10.4058 - val_mae: 2.3448\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1453 - mae: 0.7929 - val_loss: 11.0499 - val_mae: 2.4314\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2546 - mae: 0.8462 - val_loss: 11.3912 - val_mae: 2.4102\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4309 - mae: 0.9071 - val_loss: 9.6612 - val_mae: 2.2865\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8195 - mae: 1.0156 - val_loss: 10.7171 - val_mae: 2.4474\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7874 - mae: 1.0178 - val_loss: 11.2733 - val_mae: 2.4501\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4158 - mae: 0.8918 - val_loss: 9.4598 - val_mae: 2.3426\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5645 - mae: 0.9337 - val_loss: 9.4922 - val_mae: 2.2013\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1576 - mae: 0.7775 - val_loss: 11.6333 - val_mae: 2.3934\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4855 - mae: 0.9428 - val_loss: 11.2760 - val_mae: 2.3725\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4586 - mae: 0.8865 - val_loss: 10.2834 - val_mae: 2.3513\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2201 - mae: 0.8353 - val_loss: 8.8053 - val_mae: 2.2157\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2440 - mae: 0.8204 - val_loss: 9.3804 - val_mae: 2.2994\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6290 - mae: 0.9383 - val_loss: 10.7928 - val_mae: 2.5122\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6788 - mae: 1.0125 - val_loss: 8.4019 - val_mae: 2.1702\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5892 - mae: 0.9624 - val_loss: 9.9498 - val_mae: 2.3019\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3354 - mae: 0.8466 - val_loss: 9.9346 - val_mae: 2.3365\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3972 - mae: 0.8760 - val_loss: 9.2153 - val_mae: 2.2616\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3349 - mae: 0.8418 - val_loss: 10.0738 - val_mae: 2.4027\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7633 - mae: 0.9498 - val_loss: 10.9926 - val_mae: 2.3773\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8751 - mae: 0.9272 - val_loss: 10.8156 - val_mae: 2.4672\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9038 - mae: 0.9335 - val_loss: 10.7574 - val_mae: 2.4719\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.4534 - mae: 1.1850 - val_loss: 10.3195 - val_mae: 2.4792\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.3751 - mae: 1.4018 - val_loss: 10.5920 - val_mae: 2.5206\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8512 - mae: 1.0473 - val_loss: 10.0110 - val_mae: 2.4382\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1221 - mae: 1.1192 - val_loss: 10.4022 - val_mae: 2.3718\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7438 - mae: 1.0028 - val_loss: 13.3947 - val_mae: 2.6372\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8514 - mae: 1.0019 - val_loss: 10.6038 - val_mae: 2.3540\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1535 - mae: 0.8025 - val_loss: 12.1977 - val_mae: 2.4799\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1658 - mae: 0.8285 - val_loss: 10.1081 - val_mae: 2.3466\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0549 - mae: 0.7672 - val_loss: 9.7411 - val_mae: 2.2853\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9080 - mae: 0.6593 - val_loss: 10.2895 - val_mae: 2.3287\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9456 - mae: 0.6681 - val_loss: 10.7070 - val_mae: 2.3383\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9692 - mae: 0.7140 - val_loss: 9.6356 - val_mae: 2.2507\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8532 - mae: 0.6489 - val_loss: 10.5689 - val_mae: 2.3050\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8554 - mae: 0.6614 - val_loss: 10.3523 - val_mae: 2.3636\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1743 - mae: 0.7785 - val_loss: 9.7846 - val_mae: 2.3255\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2550 - mae: 0.8328 - val_loss: 10.3638 - val_mae: 2.4241\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.5370 - mae: 0.8967 - val_loss: 11.4482 - val_mae: 2.4285\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6284 - mae: 0.9563 - val_loss: 8.3425 - val_mae: 2.1681\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.8032 - mae: 1.0315 - val_loss: 10.0604 - val_mae: 2.4402\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5885 - mae: 0.9715 - val_loss: 9.5566 - val_mae: 2.3205\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5985 - mae: 0.9412 - val_loss: 10.0569 - val_mae: 2.4729\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2173 - mae: 1.4566 - val_loss: 11.5429 - val_mae: 2.6344\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8375 - mae: 1.8195 - val_loss: 11.3267 - val_mae: 2.4534\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4045 - mae: 2.0247 - val_loss: 11.0465 - val_mae: 2.4451\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.5389 - mae: 1.6516 - val_loss: 15.3050 - val_mae: 2.8418\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5421 - mae: 1.4410 - val_loss: 8.8213 - val_mae: 2.1619\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3502 - mae: 1.1777 - val_loss: 8.7448 - val_mae: 2.1114\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5925 - mae: 0.9571 - val_loss: 9.7673 - val_mae: 2.1864\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4769 - mae: 0.9293 - val_loss: 9.5915 - val_mae: 2.2395\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2185 - mae: 0.8281 - val_loss: 9.0884 - val_mae: 2.2392\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1460 - mae: 0.7787 - val_loss: 9.6463 - val_mae: 2.3021\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3855 - mae: 0.9421 - val_loss: 10.8339 - val_mae: 2.4280\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5813 - mae: 0.9665 - val_loss: 9.2789 - val_mae: 2.2192\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5269 - mae: 0.9361 - val_loss: 10.2535 - val_mae: 2.3641\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.7784 - mae: 0.9952 - val_loss: 10.4398 - val_mae: 2.4127\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7105 - mae: 0.9907 - val_loss: 8.8909 - val_mae: 2.2622\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5217 - mae: 0.9746 - val_loss: 11.1096 - val_mae: 2.5329\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7129 - mae: 1.0244 - val_loss: 9.4653 - val_mae: 2.2332\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3401 - mae: 0.8790 - val_loss: 10.5296 - val_mae: 2.4165\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6050 - mae: 0.9441 - val_loss: 12.5656 - val_mae: 2.5087\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8797 - mae: 1.0230 - val_loss: 12.7027 - val_mae: 2.6273\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7086 - mae: 0.9455 - val_loss: 10.6409 - val_mae: 2.3812\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2296 - mae: 0.8384 - val_loss: 8.0327 - val_mae: 2.1213\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0705 - mae: 0.7697 - val_loss: 10.3479 - val_mae: 2.3748\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2732 - mae: 0.7928 - val_loss: 8.6510 - val_mae: 2.1533\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4311 - mae: 0.8985 - val_loss: 10.9308 - val_mae: 2.4188\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4681 - mae: 0.9213 - val_loss: 9.4442 - val_mae: 2.2561\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3623 - mae: 0.8607 - val_loss: 9.9318 - val_mae: 2.3478\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4540 - mae: 0.9361 - val_loss: 9.9907 - val_mae: 2.3214\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3513 - mae: 0.9037 - val_loss: 9.0975 - val_mae: 2.3829\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5096 - mae: 0.9505 - val_loss: 10.8692 - val_mae: 2.4223\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2212 - mae: 0.8257 - val_loss: 9.9243 - val_mae: 2.2865\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0688 - mae: 0.7650 - val_loss: 9.5180 - val_mae: 2.2456\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2258 - mae: 0.8331 - val_loss: 11.6776 - val_mae: 2.5290\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2302 - mae: 0.8438 - val_loss: 9.1782 - val_mae: 2.2627\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3169 - mae: 0.8949 - val_loss: 9.7332 - val_mae: 2.3570\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3541 - mae: 0.8370 - val_loss: 10.1099 - val_mae: 2.3723\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1362 - mae: 0.7902 - val_loss: 9.7557 - val_mae: 2.3624\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9025 - mae: 0.7004 - val_loss: 8.8631 - val_mae: 2.2213\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9858 - mae: 0.7340 - val_loss: 11.6093 - val_mae: 2.4634\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7953 - mae: 0.6427 - val_loss: 9.3417 - val_mae: 2.2935\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7152 - mae: 0.5786 - val_loss: 10.0439 - val_mae: 2.3360\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7394 - mae: 0.6143 - val_loss: 10.3396 - val_mae: 2.3319\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7710 - mae: 0.6483 - val_loss: 8.2647 - val_mae: 2.2094\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0720 - mae: 0.7439 - val_loss: 10.4671 - val_mae: 2.4101\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3112 - mae: 0.8530 - val_loss: 9.9640 - val_mae: 2.3748\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9018 - mae: 0.6911 - val_loss: 8.7361 - val_mae: 2.2480\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8667 - mae: 0.6573 - val_loss: 10.8746 - val_mae: 2.4138\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0871 - mae: 0.7846 - val_loss: 8.8269 - val_mae: 2.2679\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9360 - mae: 0.6969 - val_loss: 9.6097 - val_mae: 2.3571\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9609 - mae: 0.7240 - val_loss: 9.3718 - val_mae: 2.2785\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1106 - mae: 0.7733 - val_loss: 10.0220 - val_mae: 2.3207\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1419 - mae: 0.7806 - val_loss: 8.6510 - val_mae: 2.2185\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0062 - mae: 0.7322 - val_loss: 9.9606 - val_mae: 2.3022\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3238 - mae: 0.9041 - val_loss: 12.1294 - val_mae: 2.5915\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2934 - mae: 1.2101 - val_loss: 10.5932 - val_mae: 2.5224\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5117 - mae: 1.2173 - val_loss: 7.9316 - val_mae: 2.1691\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.3289 - mae: 1.1077 - val_loss: 13.5033 - val_mae: 2.7032\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1438 - mae: 1.1354 - val_loss: 11.6492 - val_mae: 2.4545\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4000 - mae: 0.9042 - val_loss: 8.8560 - val_mae: 2.1734\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9028 - mae: 0.7068 - val_loss: 10.2428 - val_mae: 2.3814\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0762 - mae: 0.7921 - val_loss: 9.5315 - val_mae: 2.3289\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2654 - mae: 0.8752 - val_loss: 10.7572 - val_mae: 2.3965\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0242 - mae: 0.7554 - val_loss: 10.6730 - val_mae: 2.3426\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9018 - mae: 0.6987 - val_loss: 9.5249 - val_mae: 2.2821\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8267 - mae: 0.6722 - val_loss: 8.9617 - val_mae: 2.3198\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8380 - mae: 0.6726 - val_loss: 9.9748 - val_mae: 2.3610\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9375 - mae: 0.7066 - val_loss: 10.3906 - val_mae: 2.3634\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0118 - mae: 0.7520 - val_loss: 10.0173 - val_mae: 2.3758\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7889 - mae: 0.6594 - val_loss: 9.7663 - val_mae: 2.3057\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7970 - mae: 0.6677 - val_loss: 9.7072 - val_mae: 2.3167\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6176 - mae: 0.5692 - val_loss: 10.0808 - val_mae: 2.4014\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5802 - mae: 0.5530 - val_loss: 9.0725 - val_mae: 2.2452\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7161 - mae: 0.6175 - val_loss: 10.5645 - val_mae: 2.3656\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7722 - mae: 0.6373 - val_loss: 10.4436 - val_mae: 2.4502\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5064 - mae: 0.9664 - val_loss: 9.9975 - val_mae: 2.4528\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2113 - mae: 0.8117 - val_loss: 10.5360 - val_mae: 2.4617\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9361 - mae: 0.7421 - val_loss: 9.9014 - val_mae: 2.3774\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8582 - mae: 1.1035 - val_loss: 10.0214 - val_mae: 2.3205\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3558 - mae: 1.2240 - val_loss: 10.9252 - val_mae: 2.3690\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.3685 - mae: 1.1773 - val_loss: 9.7872 - val_mae: 2.3564\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4189 - mae: 0.9329 - val_loss: 9.9512 - val_mae: 2.4073\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2879 - mae: 0.8581 - val_loss: 9.4032 - val_mae: 2.3585\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8837 - mae: 0.7110 - val_loss: 9.0761 - val_mae: 2.2326\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1139 - mae: 0.7945 - val_loss: 10.5290 - val_mae: 2.3300\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9359 - mae: 0.7339 - val_loss: 11.0219 - val_mae: 2.4329\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9149 - mae: 0.7170 - val_loss: 9.2575 - val_mae: 2.2723\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0799 - mae: 0.7830 - val_loss: 9.0328 - val_mae: 2.3485\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0718 - mae: 0.7876 - val_loss: 9.0217 - val_mae: 2.3935\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0229 - mae: 0.7313 - val_loss: 11.7822 - val_mae: 2.4986\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9241 - mae: 0.7329 - val_loss: 8.2484 - val_mae: 2.1926\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1792 - mae: 0.7313 - val_loss: 16.3090 - val_mae: 2.7503\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3811 - mae: 0.7904 - val_loss: 8.9543 - val_mae: 2.2555\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.7089 - mae: 0.8889 - val_loss: 11.9785 - val_mae: 2.5191\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7504 - mae: 0.9379 - val_loss: 8.7323 - val_mae: 2.2421\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5107 - mae: 0.9289 - val_loss: 8.8635 - val_mae: 2.3513\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8999 - mae: 0.9487 - val_loss: 11.3140 - val_mae: 2.5044\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9400 - mae: 1.0479 - val_loss: 11.3021 - val_mae: 2.4633\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9068 - mae: 1.1039 - val_loss: 10.4512 - val_mae: 2.3488\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6156 - mae: 0.9786 - val_loss: 10.8889 - val_mae: 2.5107\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2713 - mae: 0.8812 - val_loss: 8.1101 - val_mae: 2.2210\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9967 - mae: 0.7764 - val_loss: 10.7763 - val_mae: 2.4468\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0300 - mae: 0.7402 - val_loss: 9.5450 - val_mae: 2.3106\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7868 - mae: 0.6493 - val_loss: 10.5641 - val_mae: 2.3953\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6433 - mae: 0.5893 - val_loss: 8.9488 - val_mae: 2.2497\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7348 - mae: 0.6567 - val_loss: 10.1174 - val_mae: 2.4241\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6909 - mae: 0.6203 - val_loss: 9.5896 - val_mae: 2.3254\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7696 - mae: 0.6360 - val_loss: 9.0958 - val_mae: 2.3055\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0151 - mae: 0.7556 - val_loss: 10.3177 - val_mae: 2.4983\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8263 - mae: 0.6616 - val_loss: 8.9936 - val_mae: 2.3018\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.6942 - mae: 0.6088 - val_loss: 9.6979 - val_mae: 2.3063\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6092 - mae: 0.5620 - val_loss: 9.1713 - val_mae: 2.2381\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8255 - mae: 0.7130 - val_loss: 8.9990 - val_mae: 2.2728\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.7471 - mae: 0.6341 - val_loss: 9.9386 - val_mae: 2.4336\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.5738 - mae: 0.5708 - val_loss: 9.5102 - val_mae: 2.3065\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4714 - mae: 0.4860 - val_loss: 9.1822 - val_mae: 2.2663\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4855 - mae: 0.5075 - val_loss: 9.4847 - val_mae: 2.3442\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4282 - mae: 0.4706 - val_loss: 9.5321 - val_mae: 2.3070\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.4235 - mae: 0.4405 - val_loss: 9.9377 - val_mae: 2.3211\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.5538 - mae: 0.5342 - val_loss: 9.9590 - val_mae: 2.3576\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4639 - mae: 0.4848 - val_loss: 9.4958 - val_mae: 2.3232\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.4304 - mae: 0.4516 - val_loss: 9.6987 - val_mae: 2.3151\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.4223 - mae: 0.4483 - val_loss: 9.9073 - val_mae: 2.3392\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.3968 - mae: 0.4319 - val_loss: 9.2565 - val_mae: 2.3083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1erMMEoeR0rB"
      },
      "source": [
        "### 모델 평가 \n",
        "- `evaluate()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo0n0SaZRbD1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff5d3ec3-ea1c-451f-ddfa-03bfaa64965e"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 2ms/step - loss: 13.8529 - mae: 2.5840\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[13.852914810180664, 2.5840232372283936]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl98Ql_8nvf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5278cb-300f-4d3a-a48e-83ca1205f481"
      },
      "source": [
        "print(history.history.keys()) #학습정보(히스토리)가 딕셔너리 형태로 쌓여져 있음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOgcoBclnsJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "95bdb6b0-620e-473d-871b-24c565d1ecbb"
      },
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(epochs, loss, color = 'blue', label = 'train_loss')\n",
        "ax1.plot(epochs, val_loss, color = 'red', label = 'val_loss')\n",
        "ax1.set_title('Train and Validation loss')\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "\n",
        "mae = history_dict['mae']\n",
        "val_mae = history_dict['val_mae']\n",
        "\n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(epochs, mae, color = 'blue', label = 'train_mae')\n",
        "ax2.plot(epochs, val_mae, color = 'red', label = 'val_mae')\n",
        "ax2.set_title('Train and Validation mae')\n",
        "ax2.set_xlabel('epochs')\n",
        "ax2.set_ylabel('mae')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtICFsIvVpF2"
      },
      "source": [
        "### K-Fold 교차 검증\n",
        "\n",
        "- 데이터셋의 크기가 매우 작은 경우에  \n",
        "  [훈련, 검증, 테스트] 데이터로 나누게 되면 과소적합이 일어날 확률이 높음\n",
        "\n",
        "- 이를 해결하기 위해 K-Fold 교차 검증 실행\n",
        "  <br>\n",
        "\n",
        "  <img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"600\">\n",
        "\n",
        "  <sub>출처: https://scikit-learn.org/stable/modules/cross_validation.html</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giNUN6mwWSDO"
      },
      "source": [
        "### 모델 재구성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIFRNBlYWzBc"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.layers import Input \n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60EvVZ9qR5v6"
      },
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full , y_train_full),  (x_test, y_test) = load_data(path = 'boston_housing.npz',\n",
        "                                                             test_split = 0.2,\n",
        "                                                             seed = 111)\n",
        "\n",
        "mean = np.mean(x_train_full, axis = 0)\n",
        "std = np.std(x_train_full, axis = 0)\n",
        "\n",
        "x_train_preprocessed = (x_train_full - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_preprocessed, y_train_full, \n",
        "                                                  test_size = 0.3,\n",
        "                                                  random_state = 111)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HiJbnWrWkXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2652c6d1-8741-4182-86c2-f63d8b43bdb1"
      },
      "source": [
        "k = 3\n",
        "\n",
        "kfold = KFold(n_splits= k , random_state = 111)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS3uTP6oXDzr"
      },
      "source": [
        "def build_model():\n",
        "  input = Input(shape = (13, ), name ='input')\n",
        "  hidden1 = Dense(100 , activation = 'relu', name = 'dense1')(input)\n",
        "  hidden2 = Dense(64 ,activation='relu', name = 'dense2')(hidden1)\n",
        "  hidden3 = Dense(32, activation='relu', name = 'dense3')(hidden2)\n",
        "  output = Dense(1 , name = 'output')(hidden3)\n",
        "\n",
        "  model = Model(inputs = [input], outputs = output)\n",
        "  model.compile(loss = 'mse',\n",
        "                optimizer = 'adam',\n",
        "                metrics = ['mae'])\n",
        "  \n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iMCmLyLYI2l"
      },
      "source": [
        "mae_list = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE_0YHP-YUHU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c355ea6-c84b-48de-d023-391858a548ef"
      },
      "source": [
        "for train_idx, val_idx in kfold.split(x_train_preprocessed):\n",
        "  x_train_fold , x_val_fold = x_train_preprocessed[train_idx], x_train_preprocessed[val_idx]\n",
        "  y_train_fold, y_val_fold = y_train_full[train_idx], y_train_full[val_idx]\n",
        "\n",
        "  model = build_model()\n",
        "  model.fit(x_train_fold, y_train_fold, epochs  =300,\n",
        "            validation_data = (x_val_fold, y_val_fold))\n",
        "  _, test_mae = model.evaluate(x_test, y_test)\n",
        "  mae_list.append(test_mae)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 18ms/step - loss: 537.0161 - mae: 21.4474 - val_loss: 605.7798 - val_mae: 22.5391\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 497.2296 - mae: 20.5105 - val_loss: 554.0231 - val_mae: 21.4083\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 441.5983 - mae: 19.1574 - val_loss: 473.5671 - val_mae: 19.5144\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 354.3128 - mae: 16.8218 - val_loss: 349.2275 - val_mae: 16.3432\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 235.8078 - mae: 13.2664 - val_loss: 196.7516 - val_mae: 11.6609\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 119.8469 - mae: 9.0683 - val_loss: 93.1005 - val_mae: 7.6818\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 68.7341 - mae: 6.7501 - val_loss: 76.9368 - val_mae: 6.9607\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 55.2717 - mae: 5.9005 - val_loss: 55.3584 - val_mae: 5.5786\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 37.5813 - mae: 4.7123 - val_loss: 41.8432 - val_mae: 4.6854\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29.6396 - mae: 4.0902 - val_loss: 33.8706 - val_mae: 4.1424\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 24.5873 - mae: 3.6693 - val_loss: 27.8215 - val_mae: 3.8260\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 21.9531 - mae: 3.4536 - val_loss: 25.2953 - val_mae: 3.6453\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 20.3928 - mae: 3.3211 - val_loss: 24.0378 - val_mae: 3.5244\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.3439 - mae: 3.1924 - val_loss: 23.1549 - val_mae: 3.4302\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 18.4110 - mae: 3.0825 - val_loss: 22.4700 - val_mae: 3.3606\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.6426 - mae: 3.0405 - val_loss: 21.5846 - val_mae: 3.3157\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.7582 - mae: 2.9583 - val_loss: 21.0828 - val_mae: 3.2696\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 16.0952 - mae: 2.8937 - val_loss: 20.2181 - val_mae: 3.2162\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.3717 - mae: 2.8340 - val_loss: 19.6108 - val_mae: 3.1499\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 14.8127 - mae: 2.7927 - val_loss: 18.8594 - val_mae: 3.1093\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.3229 - mae: 2.7272 - val_loss: 19.0194 - val_mae: 3.0838\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 13.7812 - mae: 2.6599 - val_loss: 18.2085 - val_mae: 3.0195\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 13.2952 - mae: 2.6220 - val_loss: 17.9225 - val_mae: 2.9933\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.8295 - mae: 2.5646 - val_loss: 17.7722 - val_mae: 2.9526\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 12.4156 - mae: 2.5041 - val_loss: 17.3512 - val_mae: 2.9012\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.0730 - mae: 2.4539 - val_loss: 16.8524 - val_mae: 2.8442\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.0652 - mae: 2.5063 - val_loss: 16.3766 - val_mae: 2.8255\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.5285 - mae: 2.3964 - val_loss: 16.8075 - val_mae: 2.8102\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.1656 - mae: 2.3734 - val_loss: 16.1000 - val_mae: 2.8205\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 11.0005 - mae: 2.3938 - val_loss: 15.7912 - val_mae: 2.8019\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 10.6484 - mae: 2.3194 - val_loss: 15.9661 - val_mae: 2.7716\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6064 - mae: 2.3094 - val_loss: 15.5261 - val_mae: 2.7753\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.2198 - mae: 2.2689 - val_loss: 15.4600 - val_mae: 2.7400\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.0617 - mae: 2.2380 - val_loss: 15.3004 - val_mae: 2.7227\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.9320 - mae: 2.2348 - val_loss: 14.9343 - val_mae: 2.7080\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7699 - mae: 2.2165 - val_loss: 14.8624 - val_mae: 2.7128\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6016 - mae: 2.2074 - val_loss: 14.4532 - val_mae: 2.6498\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.4410 - mae: 2.1871 - val_loss: 14.4373 - val_mae: 2.6303\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2989 - mae: 2.1620 - val_loss: 14.4686 - val_mae: 2.6445\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.2258 - mae: 2.1495 - val_loss: 14.2353 - val_mae: 2.6148\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.1023 - mae: 2.1497 - val_loss: 14.0506 - val_mae: 2.6473\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 9.0294 - mae: 2.1340 - val_loss: 13.9983 - val_mae: 2.5600\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.9933 - mae: 2.1216 - val_loss: 13.6222 - val_mae: 2.5902\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.8209 - mae: 2.0904 - val_loss: 13.7622 - val_mae: 2.5741\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6217 - mae: 2.0643 - val_loss: 13.6161 - val_mae: 2.5953\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.6078 - mae: 2.0840 - val_loss: 13.5038 - val_mae: 2.6068\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4814 - mae: 2.0623 - val_loss: 13.4338 - val_mae: 2.5155\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.5333 - mae: 2.0474 - val_loss: 13.2985 - val_mae: 2.5598\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.2734 - mae: 2.0320 - val_loss: 13.1094 - val_mae: 2.5911\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.2763 - mae: 2.0214 - val_loss: 13.1147 - val_mae: 2.5133\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 8.2524 - mae: 2.0220 - val_loss: 13.0005 - val_mae: 2.5251\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.1168 - mae: 2.0096 - val_loss: 12.7318 - val_mae: 2.5249\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8911 - mae: 1.9802 - val_loss: 12.9680 - val_mae: 2.4796\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.9132 - mae: 1.9909 - val_loss: 12.4715 - val_mae: 2.5029\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7938 - mae: 1.9762 - val_loss: 12.3435 - val_mae: 2.4609\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7986 - mae: 1.9644 - val_loss: 12.3223 - val_mae: 2.4596\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.7707 - mae: 1.9459 - val_loss: 12.3465 - val_mae: 2.4556\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.7006 - mae: 1.9615 - val_loss: 12.3541 - val_mae: 2.4949\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5330 - mae: 1.9395 - val_loss: 12.2374 - val_mae: 2.4121\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.7429 - mae: 1.9378 - val_loss: 12.0367 - val_mae: 2.3913\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.3702 - mae: 1.9035 - val_loss: 12.0886 - val_mae: 2.4821\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.4672 - mae: 1.9383 - val_loss: 12.0428 - val_mae: 2.4370\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2866 - mae: 1.9101 - val_loss: 12.1056 - val_mae: 2.4110\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.3136 - mae: 1.8866 - val_loss: 11.8358 - val_mae: 2.3937\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.2041 - mae: 1.8842 - val_loss: 11.9211 - val_mae: 2.4134\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2521 - mae: 1.8979 - val_loss: 11.7507 - val_mae: 2.3839\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0572 - mae: 1.8526 - val_loss: 11.7183 - val_mae: 2.3552\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.0869 - mae: 1.8599 - val_loss: 11.9306 - val_mae: 2.4074\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 7.0438 - mae: 1.8666 - val_loss: 11.7897 - val_mae: 2.3635\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.0105 - mae: 1.8604 - val_loss: 11.3983 - val_mae: 2.3557\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.8800 - mae: 1.8381 - val_loss: 11.3862 - val_mae: 2.3381\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.9295 - mae: 1.8401 - val_loss: 11.4343 - val_mae: 2.3206\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.8043 - mae: 1.8298 - val_loss: 11.4507 - val_mae: 2.3807\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7123 - mae: 1.8279 - val_loss: 11.2192 - val_mae: 2.3251\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7292 - mae: 1.8158 - val_loss: 11.0298 - val_mae: 2.2989\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6329 - mae: 1.8163 - val_loss: 11.0967 - val_mae: 2.3248\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.6598 - mae: 1.8112 - val_loss: 10.9727 - val_mae: 2.3085\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.6508 - mae: 1.8106 - val_loss: 11.0659 - val_mae: 2.3326\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.5410 - mae: 1.8047 - val_loss: 11.0590 - val_mae: 2.3137\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.4425 - mae: 1.7827 - val_loss: 10.9641 - val_mae: 2.2958\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4463 - mae: 1.7893 - val_loss: 10.8338 - val_mae: 2.2868\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.9352 - mae: 1.8402 - val_loss: 11.1242 - val_mae: 2.3679\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7251 - mae: 1.8058 - val_loss: 11.0075 - val_mae: 2.2779\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 6.5845 - mae: 1.8025 - val_loss: 11.1531 - val_mae: 2.3825\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.4039 - mae: 1.7928 - val_loss: 10.7982 - val_mae: 2.2517\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.3323 - mae: 1.7629 - val_loss: 10.6436 - val_mae: 2.2831\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.5229 - mae: 1.8175 - val_loss: 11.0262 - val_mae: 2.3431\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1716 - mae: 1.7581 - val_loss: 10.6399 - val_mae: 2.2622\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.0482 - mae: 1.7264 - val_loss: 10.5201 - val_mae: 2.2821\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3111 - mae: 1.7812 - val_loss: 10.6579 - val_mae: 2.2565\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4581 - mae: 1.7949 - val_loss: 10.3503 - val_mae: 2.2368\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0601 - mae: 1.7682 - val_loss: 10.4048 - val_mae: 2.2655\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.9844 - mae: 1.7332 - val_loss: 10.4740 - val_mae: 2.2170\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9189 - mae: 1.7158 - val_loss: 10.3070 - val_mae: 2.2353\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9653 - mae: 1.7326 - val_loss: 10.1600 - val_mae: 2.2311\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0390 - mae: 1.7288 - val_loss: 10.3169 - val_mae: 2.2023\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7642 - mae: 1.6998 - val_loss: 10.0498 - val_mae: 2.2583\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7941 - mae: 1.7207 - val_loss: 10.0584 - val_mae: 2.2170\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6906 - mae: 1.6767 - val_loss: 10.1677 - val_mae: 2.2310\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.6670 - mae: 1.6891 - val_loss: 10.2748 - val_mae: 2.2425\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7213 - mae: 1.7058 - val_loss: 9.8916 - val_mae: 2.1769\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7243 - mae: 1.6886 - val_loss: 9.9134 - val_mae: 2.2044\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.6717 - mae: 1.6755 - val_loss: 10.0136 - val_mae: 2.2209\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5163 - mae: 1.6562 - val_loss: 10.0715 - val_mae: 2.2305\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.4624 - mae: 1.6669 - val_loss: 9.8289 - val_mae: 2.2050\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4737 - mae: 1.6475 - val_loss: 10.0754 - val_mae: 2.1768\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.5121 - mae: 1.6453 - val_loss: 10.0886 - val_mae: 2.2418\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3793 - mae: 1.6415 - val_loss: 9.7718 - val_mae: 2.1692\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.5326 - mae: 1.6563 - val_loss: 9.7544 - val_mae: 2.1926\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.4424 - mae: 1.6435 - val_loss: 9.6256 - val_mae: 2.1642\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2643 - mae: 1.6224 - val_loss: 9.7751 - val_mae: 2.2057\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.3483 - mae: 1.6520 - val_loss: 9.9385 - val_mae: 2.1736\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3551 - mae: 1.6311 - val_loss: 9.6360 - val_mae: 2.1755\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0019 - mae: 1.7495 - val_loss: 9.6075 - val_mae: 2.2034\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2409 - mae: 1.6323 - val_loss: 9.7048 - val_mae: 2.1370\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1952 - mae: 1.6033 - val_loss: 9.4241 - val_mae: 2.1581\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.1156 - mae: 1.6042 - val_loss: 9.4570 - val_mae: 2.1627\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2692 - mae: 1.6203 - val_loss: 9.2881 - val_mae: 2.1075\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2476 - mae: 1.6276 - val_loss: 9.6135 - val_mae: 2.1782\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.0446 - mae: 1.5951 - val_loss: 9.2642 - val_mae: 2.1061\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9861 - mae: 1.5791 - val_loss: 9.4236 - val_mae: 2.1647\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9045 - mae: 1.5669 - val_loss: 9.4520 - val_mae: 2.1282\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9956 - mae: 1.5847 - val_loss: 9.1050 - val_mae: 2.1389\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.9084 - mae: 1.5870 - val_loss: 9.0855 - val_mae: 2.0961\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.9072 - mae: 1.5576 - val_loss: 9.2471 - val_mae: 2.1218\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8927 - mae: 1.5702 - val_loss: 9.3070 - val_mae: 2.1612\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8342 - mae: 1.5483 - val_loss: 9.1877 - val_mae: 2.1107\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 5.0331 - mae: 1.5697 - val_loss: 9.2089 - val_mae: 2.1051\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2290 - mae: 1.6112 - val_loss: 9.0905 - val_mae: 2.1273\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.8519 - mae: 1.5565 - val_loss: 9.2434 - val_mae: 2.1757\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7842 - mae: 1.5426 - val_loss: 9.2930 - val_mae: 2.1057\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6121 - mae: 1.5140 - val_loss: 8.9624 - val_mae: 2.1067\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6940 - mae: 1.5287 - val_loss: 8.9725 - val_mae: 2.0926\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6393 - mae: 1.5306 - val_loss: 9.1421 - val_mae: 2.1300\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4889 - mae: 1.5008 - val_loss: 8.8707 - val_mae: 2.0693\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 4.5380 - mae: 1.5084 - val_loss: 8.7779 - val_mae: 2.0686\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4769 - mae: 1.4916 - val_loss: 8.7806 - val_mae: 2.0833\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5725 - mae: 1.5186 - val_loss: 8.8944 - val_mae: 2.0922\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.6287 - mae: 1.5099 - val_loss: 8.9255 - val_mae: 2.0814\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4884 - mae: 1.5000 - val_loss: 8.9872 - val_mae: 2.1188\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.3376 - mae: 1.4717 - val_loss: 8.8678 - val_mae: 2.0677\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4582 - mae: 1.4772 - val_loss: 8.6673 - val_mae: 2.0703\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3137 - mae: 1.4672 - val_loss: 8.7348 - val_mae: 2.0682\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.2604 - mae: 1.4467 - val_loss: 8.6394 - val_mae: 2.0533\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4639 - mae: 1.4785 - val_loss: 8.9388 - val_mae: 2.1025\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4414 - mae: 1.5006 - val_loss: 8.7686 - val_mae: 2.0552\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.4273 - mae: 1.4912 - val_loss: 8.6665 - val_mae: 2.0937\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.4217 - mae: 1.4922 - val_loss: 8.6525 - val_mae: 2.0365\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3838 - mae: 1.5147 - val_loss: 8.7194 - val_mae: 2.0981\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1373 - mae: 1.4420 - val_loss: 8.5950 - val_mae: 2.0321\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9841 - mae: 1.4028 - val_loss: 8.3914 - val_mae: 2.0381\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0245 - mae: 1.4261 - val_loss: 8.6392 - val_mae: 2.0696\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9640 - mae: 1.4209 - val_loss: 8.5355 - val_mae: 2.0738\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8544 - mae: 1.3845 - val_loss: 8.6802 - val_mae: 2.0329\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9542 - mae: 1.4052 - val_loss: 8.5131 - val_mae: 2.0652\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0207 - mae: 1.4335 - val_loss: 8.6506 - val_mae: 2.0448\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8500 - mae: 1.3845 - val_loss: 8.3551 - val_mae: 2.0440\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8313 - mae: 1.3855 - val_loss: 8.4160 - val_mae: 2.0408\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9662 - mae: 1.4067 - val_loss: 8.5142 - val_mae: 2.0600\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9696 - mae: 1.4106 - val_loss: 8.3918 - val_mae: 2.0635\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7536 - mae: 1.3784 - val_loss: 8.4855 - val_mae: 2.0609\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6931 - mae: 1.3666 - val_loss: 8.4882 - val_mae: 2.0505\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6686 - mae: 1.3322 - val_loss: 8.4257 - val_mae: 2.0397\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5939 - mae: 1.3314 - val_loss: 8.4418 - val_mae: 2.0724\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6135 - mae: 1.3288 - val_loss: 8.6760 - val_mae: 2.0541\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6809 - mae: 1.3604 - val_loss: 8.4427 - val_mae: 2.0971\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6756 - mae: 1.3514 - val_loss: 8.4744 - val_mae: 2.0794\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.7124 - mae: 1.3636 - val_loss: 8.6054 - val_mae: 2.0743\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.8972 - mae: 1.4063 - val_loss: 8.2771 - val_mae: 2.0548\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.6679 - mae: 1.3825 - val_loss: 8.8610 - val_mae: 2.1101\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5448 - mae: 1.3178 - val_loss: 8.7513 - val_mae: 2.1200\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.5602 - mae: 1.3331 - val_loss: 8.7572 - val_mae: 2.0785\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4056 - mae: 1.3015 - val_loss: 8.4845 - val_mae: 2.0646\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4557 - mae: 1.3078 - val_loss: 8.4071 - val_mae: 2.0516\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3848 - mae: 1.3030 - val_loss: 8.3346 - val_mae: 2.0316\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3181 - mae: 1.2732 - val_loss: 8.3883 - val_mae: 2.0785\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2445 - mae: 1.2769 - val_loss: 8.6408 - val_mae: 2.0960\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.2949 - mae: 1.2716 - val_loss: 8.3987 - val_mae: 2.0469\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9505 - mae: 1.4132 - val_loss: 8.9178 - val_mae: 2.1167\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6778 - mae: 1.3883 - val_loss: 8.4096 - val_mae: 2.0938\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2977 - mae: 1.3124 - val_loss: 8.5421 - val_mae: 2.0780\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.1574 - mae: 1.2585 - val_loss: 8.4239 - val_mae: 2.0558\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1213 - mae: 1.2564 - val_loss: 8.4352 - val_mae: 2.0857\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0311 - mae: 1.2500 - val_loss: 8.5406 - val_mae: 2.0753\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1189 - mae: 1.2670 - val_loss: 8.5792 - val_mae: 2.0505\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0450 - mae: 1.2455 - val_loss: 8.7109 - val_mae: 2.1498\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.9299 - mae: 1.2183 - val_loss: 8.9398 - val_mae: 2.1106\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9977 - mae: 1.2233 - val_loss: 8.4673 - val_mae: 2.0747\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8367 - mae: 1.1890 - val_loss: 8.6372 - val_mae: 2.1064\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9081 - mae: 1.2096 - val_loss: 8.8212 - val_mae: 2.1029\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8620 - mae: 1.1955 - val_loss: 8.6601 - val_mae: 2.0941\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7413 - mae: 1.1711 - val_loss: 8.7642 - val_mae: 2.1185\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7659 - mae: 1.1689 - val_loss: 8.7527 - val_mae: 2.1010\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7763 - mae: 1.1458 - val_loss: 8.7372 - val_mae: 2.1287\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6805 - mae: 1.1522 - val_loss: 9.0159 - val_mae: 2.0867\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8182 - mae: 1.1984 - val_loss: 8.6567 - val_mae: 2.1165\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8273 - mae: 1.1977 - val_loss: 8.6957 - val_mae: 2.1183\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6973 - mae: 1.1885 - val_loss: 9.1164 - val_mae: 2.0958\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8959 - mae: 1.2215 - val_loss: 8.5696 - val_mae: 2.1108\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8943 - mae: 1.2149 - val_loss: 8.4783 - val_mae: 2.0782\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5623 - mae: 1.1409 - val_loss: 8.6691 - val_mae: 2.0706\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5139 - mae: 1.1130 - val_loss: 8.7352 - val_mae: 2.1122\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6042 - mae: 1.1439 - val_loss: 8.6087 - val_mae: 2.0814\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4321 - mae: 1.0903 - val_loss: 8.8388 - val_mae: 2.1166\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6577 - mae: 1.1593 - val_loss: 9.1867 - val_mae: 2.1529\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5681 - mae: 1.1541 - val_loss: 8.8971 - val_mae: 2.1164\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4881 - mae: 1.1087 - val_loss: 8.8985 - val_mae: 2.1029\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4862 - mae: 1.1138 - val_loss: 8.8457 - val_mae: 2.0851\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4644 - mae: 1.0875 - val_loss: 8.7546 - val_mae: 2.1092\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3511 - mae: 1.0623 - val_loss: 8.8681 - val_mae: 2.1135\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.2607 - mae: 1.0441 - val_loss: 8.7764 - val_mae: 2.1050\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3412 - mae: 1.0718 - val_loss: 8.9050 - val_mae: 2.1326\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3546 - mae: 1.0737 - val_loss: 8.7724 - val_mae: 2.1145\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7026 - mae: 1.1783 - val_loss: 10.3210 - val_mae: 2.2443\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 3.0343 - mae: 1.2845 - val_loss: 8.9724 - val_mae: 2.2273\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8466 - mae: 1.2579 - val_loss: 9.3948 - val_mae: 2.1648\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 2.7998 - mae: 1.2303 - val_loss: 9.1810 - val_mae: 2.1817\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5768 - mae: 1.1678 - val_loss: 9.1414 - val_mae: 2.1593\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1230 - mae: 1.0266 - val_loss: 9.0313 - val_mae: 2.1332\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.3847 - mae: 1.1088 - val_loss: 8.9876 - val_mae: 2.1423\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.3032 - mae: 1.1141 - val_loss: 9.0034 - val_mae: 2.1824\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0996 - mae: 1.0216 - val_loss: 8.9594 - val_mae: 2.0785\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0556 - mae: 1.0247 - val_loss: 8.8763 - val_mae: 2.1390\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0318 - mae: 0.9815 - val_loss: 9.0688 - val_mae: 2.1289\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0445 - mae: 0.9813 - val_loss: 8.9736 - val_mae: 2.1364\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0944 - mae: 1.0266 - val_loss: 9.3018 - val_mae: 2.1706\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9832 - mae: 0.9886 - val_loss: 8.9605 - val_mae: 2.1332\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9832 - mae: 0.9826 - val_loss: 8.9703 - val_mae: 2.1035\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0696 - mae: 1.0005 - val_loss: 8.8296 - val_mae: 2.1154\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0783 - mae: 1.0435 - val_loss: 9.5960 - val_mae: 2.1758\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0554 - mae: 1.0473 - val_loss: 8.9011 - val_mae: 2.1299\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9122 - mae: 0.9657 - val_loss: 9.0076 - val_mae: 2.1234\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.8597 - mae: 0.9376 - val_loss: 9.1757 - val_mae: 2.1382\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9124 - mae: 0.9912 - val_loss: 8.9165 - val_mae: 2.1565\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8534 - mae: 0.9595 - val_loss: 8.9291 - val_mae: 2.1265\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.0368 - mae: 1.0201 - val_loss: 9.2291 - val_mae: 2.1241\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.8074 - mae: 0.9512 - val_loss: 9.1646 - val_mae: 2.1953\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7943 - mae: 0.9372 - val_loss: 9.1603 - val_mae: 2.1319\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7596 - mae: 0.9254 - val_loss: 9.2218 - val_mae: 2.1960\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7769 - mae: 0.9336 - val_loss: 9.1304 - val_mae: 2.1287\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8390 - mae: 0.9801 - val_loss: 9.8394 - val_mae: 2.1910\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9630 - mae: 1.0469 - val_loss: 8.9737 - val_mae: 2.1767\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.8875 - mae: 0.9819 - val_loss: 9.0664 - val_mae: 2.1727\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7336 - mae: 0.9192 - val_loss: 9.4209 - val_mae: 2.1528\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6475 - mae: 0.8835 - val_loss: 8.9458 - val_mae: 2.1464\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6556 - mae: 0.8817 - val_loss: 9.1000 - val_mae: 2.1428\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6065 - mae: 0.8715 - val_loss: 9.2685 - val_mae: 2.1818\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7594 - mae: 0.9578 - val_loss: 8.9609 - val_mae: 2.1472\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6533 - mae: 0.9161 - val_loss: 9.1991 - val_mae: 2.1609\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5613 - mae: 0.8589 - val_loss: 9.2662 - val_mae: 2.1494\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6144 - mae: 0.8965 - val_loss: 8.8524 - val_mae: 2.1185\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6353 - mae: 0.9099 - val_loss: 8.9927 - val_mae: 2.1782\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6337 - mae: 0.9140 - val_loss: 9.3410 - val_mae: 2.1563\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5074 - mae: 0.8520 - val_loss: 9.0920 - val_mae: 2.1731\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4762 - mae: 0.8447 - val_loss: 9.4470 - val_mae: 2.1602\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5421 - mae: 0.8819 - val_loss: 9.2312 - val_mae: 2.1901\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4717 - mae: 0.8466 - val_loss: 9.3243 - val_mae: 2.1392\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4923 - mae: 0.8544 - val_loss: 9.3131 - val_mae: 2.2199\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5089 - mae: 0.8626 - val_loss: 9.3617 - val_mae: 2.1914\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4267 - mae: 0.8374 - val_loss: 9.7511 - val_mae: 2.1904\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5411 - mae: 0.8803 - val_loss: 9.4281 - val_mae: 2.2279\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4085 - mae: 0.8413 - val_loss: 9.2948 - val_mae: 2.1550\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4215 - mae: 0.8346 - val_loss: 9.3643 - val_mae: 2.1596\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4449 - mae: 0.8366 - val_loss: 9.8713 - val_mae: 2.1696\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5550 - mae: 0.9292 - val_loss: 9.1724 - val_mae: 2.1570\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.3610 - mae: 0.8308 - val_loss: 9.3833 - val_mae: 2.1958\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4053 - mae: 0.8274 - val_loss: 9.3145 - val_mae: 2.1760\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3229 - mae: 0.8070 - val_loss: 9.6195 - val_mae: 2.1927\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4133 - mae: 0.8486 - val_loss: 10.0191 - val_mae: 2.2159\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5492 - mae: 0.8844 - val_loss: 9.2960 - val_mae: 2.1956\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3469 - mae: 0.8147 - val_loss: 9.3820 - val_mae: 2.1760\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3623 - mae: 0.8294 - val_loss: 9.9329 - val_mae: 2.1758\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6092 - mae: 0.9144 - val_loss: 9.4093 - val_mae: 2.2006\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3188 - mae: 0.8128 - val_loss: 9.5132 - val_mae: 2.1965\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2132 - mae: 0.7839 - val_loss: 9.8744 - val_mae: 2.2032\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3662 - mae: 0.8228 - val_loss: 9.2696 - val_mae: 2.1425\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1821 - mae: 0.7719 - val_loss: 9.2835 - val_mae: 2.1863\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1536 - mae: 0.7471 - val_loss: 9.9729 - val_mae: 2.1896\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4346 - mae: 0.8603 - val_loss: 9.6287 - val_mae: 2.1988\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2122 - mae: 0.8031 - val_loss: 9.6299 - val_mae: 2.2182\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5081 - mae: 0.9154 - val_loss: 9.5997 - val_mae: 2.1995\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2857 - mae: 0.8504 - val_loss: 10.0392 - val_mae: 2.2097\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2601 - mae: 0.8026 - val_loss: 9.4693 - val_mae: 2.2073\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2805 - mae: 0.8258 - val_loss: 9.6937 - val_mae: 2.2127\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4248 - mae: 0.8839 - val_loss: 10.2009 - val_mae: 2.2735\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2839 - mae: 0.8244 - val_loss: 9.4329 - val_mae: 2.1775\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1665 - mae: 0.7747 - val_loss: 9.9279 - val_mae: 2.2291\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2063 - mae: 0.7983 - val_loss: 10.6656 - val_mae: 2.2707\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4147 - mae: 0.8760 - val_loss: 9.4578 - val_mae: 2.2238\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3744 - mae: 0.8327 - val_loss: 9.5910 - val_mae: 2.2277\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2038 - mae: 0.7556 - val_loss: 9.6916 - val_mae: 2.1865\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1079 - mae: 0.7374 - val_loss: 10.1462 - val_mae: 2.2455\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0484 - mae: 0.6980 - val_loss: 9.6724 - val_mae: 2.1621\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0576 - mae: 0.7316 - val_loss: 9.7078 - val_mae: 2.2562\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0860 - mae: 0.7269 - val_loss: 9.7860 - val_mae: 2.1743\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0501 - mae: 0.7136 - val_loss: 10.0766 - val_mae: 2.2432\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1642 - mae: 0.7542 - val_loss: 10.0007 - val_mae: 2.2302\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2629 - mae: 0.7991 - val_loss: 9.9308 - val_mae: 2.2468\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1490 - mae: 0.7682 - val_loss: 9.8640 - val_mae: 2.2676\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0771 - mae: 0.7489 - val_loss: 10.1773 - val_mae: 2.2406\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 14.4582 - mae: 2.8397\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 20ms/step - loss: 553.9595 - mae: 21.5372 - val_loss: 550.1148 - val_mae: 21.4959\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 492.1800 - mae: 20.0993 - val_loss: 476.4005 - val_mae: 19.7554\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 410.6663 - mae: 17.9866 - val_loss: 376.3806 - val_mae: 17.1170\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 300.0716 - mae: 14.8845 - val_loss: 246.1483 - val_mae: 13.5601\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 177.5290 - mae: 11.0167 - val_loss: 118.6943 - val_mae: 9.2584\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 88.1913 - mae: 7.5066 - val_loss: 57.8291 - val_mae: 6.1993\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 65.7186 - mae: 6.2469 - val_loss: 40.1514 - val_mae: 5.0731\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 45.7657 - mae: 5.1402 - val_loss: 30.8196 - val_mae: 4.5052\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 34.6559 - mae: 4.3492 - val_loss: 26.7654 - val_mae: 4.1231\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 28.6732 - mae: 3.8989 - val_loss: 23.3708 - val_mae: 3.7551\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 24.5669 - mae: 3.5878 - val_loss: 21.9637 - val_mae: 3.6505\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 22.6836 - mae: 3.4116 - val_loss: 20.8999 - val_mae: 3.5515\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 21.1138 - mae: 3.2443 - val_loss: 19.8096 - val_mae: 3.4280\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 19.9606 - mae: 3.0942 - val_loss: 18.8387 - val_mae: 3.3396\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.0137 - mae: 3.0046 - val_loss: 17.8002 - val_mae: 3.2790\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 17.8517 - mae: 2.9511 - val_loss: 16.8579 - val_mae: 3.2097\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 17.0917 - mae: 2.8731 - val_loss: 16.2644 - val_mae: 3.1195\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 16.4317 - mae: 2.8213 - val_loss: 15.5085 - val_mae: 3.0634\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 15.5067 - mae: 2.7235 - val_loss: 15.1011 - val_mae: 3.0184\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.8968 - mae: 2.6666 - val_loss: 14.6057 - val_mae: 2.9730\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 14.6022 - mae: 2.6080 - val_loss: 14.2285 - val_mae: 2.8939\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.9127 - mae: 2.5780 - val_loss: 13.5662 - val_mae: 2.8980\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 13.3569 - mae: 2.5509 - val_loss: 13.1151 - val_mae: 2.8680\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.6623 - mae: 2.4333 - val_loss: 13.0825 - val_mae: 2.8208\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 12.4533 - mae: 2.3979 - val_loss: 12.6241 - val_mae: 2.7852\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.9684 - mae: 2.3789 - val_loss: 12.0497 - val_mae: 2.7673\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.5766 - mae: 2.3669 - val_loss: 11.7988 - val_mae: 2.7093\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.3432 - mae: 2.2895 - val_loss: 11.5370 - val_mae: 2.6931\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 10.8060 - mae: 2.3020 - val_loss: 11.5292 - val_mae: 2.6663\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.6126 - mae: 2.2691 - val_loss: 11.2881 - val_mae: 2.6396\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.5190 - mae: 2.2216 - val_loss: 11.1596 - val_mae: 2.6296\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.4038 - mae: 2.2396 - val_loss: 11.1145 - val_mae: 2.6332\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.9123 - mae: 2.1606 - val_loss: 10.7503 - val_mae: 2.5695\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.6994 - mae: 2.1427 - val_loss: 10.7782 - val_mae: 2.5755\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.6011 - mae: 2.1574 - val_loss: 10.8332 - val_mae: 2.6069\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2309 - mae: 2.1073 - val_loss: 10.7091 - val_mae: 2.5571\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 9.4243 - mae: 2.1343 - val_loss: 10.4712 - val_mae: 2.5349\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.9703 - mae: 2.1005 - val_loss: 10.4501 - val_mae: 2.5341\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.8105 - mae: 2.0603 - val_loss: 10.2077 - val_mae: 2.5115\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.6892 - mae: 2.0428 - val_loss: 10.2087 - val_mae: 2.5069\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.9568 - mae: 2.1394 - val_loss: 10.5124 - val_mae: 2.4958\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.3669 - mae: 2.0429 - val_loss: 10.3143 - val_mae: 2.5311\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.5021 - mae: 2.0218 - val_loss: 10.2469 - val_mae: 2.5131\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.1629 - mae: 1.9910 - val_loss: 10.3287 - val_mae: 2.5203\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.9472 - mae: 1.9739 - val_loss: 10.1537 - val_mae: 2.4760\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.9950 - mae: 2.0030 - val_loss: 10.1588 - val_mae: 2.4807\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 7.8892 - mae: 1.9598 - val_loss: 10.2294 - val_mae: 2.4954\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.7756 - mae: 1.9513 - val_loss: 10.3394 - val_mae: 2.5126\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.6277 - mae: 1.9354 - val_loss: 10.3212 - val_mae: 2.5079\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6786 - mae: 1.9772 - val_loss: 10.4191 - val_mae: 2.5114\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3388 - mae: 1.8950 - val_loss: 10.3041 - val_mae: 2.5127\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.2849 - mae: 1.8978 - val_loss: 10.2845 - val_mae: 2.4740\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.4418 - mae: 1.9352 - val_loss: 10.4781 - val_mae: 2.5231\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5171 - mae: 1.9360 - val_loss: 10.2693 - val_mae: 2.5071\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.0860 - mae: 1.8698 - val_loss: 10.6335 - val_mae: 2.5044\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.9437 - mae: 1.8488 - val_loss: 10.1329 - val_mae: 2.4867\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7920 - mae: 1.8151 - val_loss: 10.1801 - val_mae: 2.4883\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.6360 - mae: 1.7974 - val_loss: 10.4015 - val_mae: 2.4783\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.8484 - mae: 1.8830 - val_loss: 10.3286 - val_mae: 2.4880\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.7636 - mae: 1.7836 - val_loss: 10.1585 - val_mae: 2.5168\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.4798 - mae: 1.7838 - val_loss: 10.5267 - val_mae: 2.4701\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.4138 - mae: 1.7770 - val_loss: 10.2366 - val_mae: 2.5000\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1982 - mae: 1.7381 - val_loss: 10.5890 - val_mae: 2.4941\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2603 - mae: 1.7406 - val_loss: 10.2843 - val_mae: 2.5116\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0385 - mae: 1.7068 - val_loss: 10.5554 - val_mae: 2.4998\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.3318 - mae: 1.7959 - val_loss: 10.3456 - val_mae: 2.5212\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.0289 - mae: 1.6943 - val_loss: 10.1132 - val_mae: 2.4903\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8729 - mae: 1.6808 - val_loss: 10.5066 - val_mae: 2.4978\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8858 - mae: 1.7099 - val_loss: 10.3331 - val_mae: 2.5041\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8198 - mae: 1.6775 - val_loss: 10.6781 - val_mae: 2.4935\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.7210 - mae: 1.7044 - val_loss: 10.3992 - val_mae: 2.5113\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7059 - mae: 1.6664 - val_loss: 10.6180 - val_mae: 2.5220\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.4332 - mae: 1.6450 - val_loss: 10.6251 - val_mae: 2.5287\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.4265 - mae: 1.6325 - val_loss: 10.5591 - val_mae: 2.5270\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3992 - mae: 1.6281 - val_loss: 10.5970 - val_mae: 2.4998\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2422 - mae: 1.6009 - val_loss: 10.4815 - val_mae: 2.5135\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3091 - mae: 1.5940 - val_loss: 10.6237 - val_mae: 2.5265\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.2387 - mae: 1.5861 - val_loss: 10.6872 - val_mae: 2.5415\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.1732 - mae: 1.5943 - val_loss: 10.6967 - val_mae: 2.5438\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.2647 - mae: 1.6231 - val_loss: 10.7557 - val_mae: 2.5441\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2372 - mae: 1.5921 - val_loss: 10.4906 - val_mae: 2.5285\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.8043 - mae: 1.7391 - val_loss: 11.3119 - val_mae: 2.5240\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.1938 - mae: 1.5888 - val_loss: 10.7787 - val_mae: 2.5645\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0866 - mae: 1.5942 - val_loss: 11.1166 - val_mae: 2.5276\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9867 - mae: 1.6111 - val_loss: 10.7432 - val_mae: 2.5191\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9323 - mae: 1.6037 - val_loss: 10.9012 - val_mae: 2.5526\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0618 - mae: 1.6318 - val_loss: 10.8192 - val_mae: 2.5294\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6401 - mae: 1.5245 - val_loss: 10.9771 - val_mae: 2.5436\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5765 - mae: 1.5225 - val_loss: 11.1549 - val_mae: 2.5504\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6678 - mae: 1.5567 - val_loss: 10.9744 - val_mae: 2.5432\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.6036 - mae: 1.5116 - val_loss: 11.2297 - val_mae: 2.5417\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4949 - mae: 1.4914 - val_loss: 11.0212 - val_mae: 2.5405\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.5004 - mae: 1.4948 - val_loss: 11.1380 - val_mae: 2.5841\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5247 - mae: 1.5157 - val_loss: 11.0780 - val_mae: 2.5628\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4298 - mae: 1.5326 - val_loss: 11.5839 - val_mae: 2.5730\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.2847 - mae: 1.4655 - val_loss: 10.9216 - val_mae: 2.5556\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.1724 - mae: 1.4559 - val_loss: 11.6129 - val_mae: 2.5490\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.1242 - mae: 1.4504 - val_loss: 11.1291 - val_mae: 2.5431\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0763 - mae: 1.4282 - val_loss: 11.1501 - val_mae: 2.5102\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.1512 - mae: 1.4550 - val_loss: 11.3361 - val_mae: 2.5687\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.0997 - mae: 1.4630 - val_loss: 11.5429 - val_mae: 2.5900\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.1547 - mae: 1.4702 - val_loss: 11.4002 - val_mae: 2.5910\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0264 - mae: 1.4146 - val_loss: 11.0304 - val_mae: 2.4850\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.3650 - mae: 1.5066 - val_loss: 11.1964 - val_mae: 2.5527\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.8055 - mae: 1.4091 - val_loss: 11.3181 - val_mae: 2.5464\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9684 - mae: 1.4189 - val_loss: 11.4537 - val_mae: 2.5874\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.9656 - mae: 1.4178 - val_loss: 11.5061 - val_mae: 2.5587\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8043 - mae: 1.3799 - val_loss: 11.4573 - val_mae: 2.5459\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0912 - mae: 1.4786 - val_loss: 11.5830 - val_mae: 2.5973\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9795 - mae: 1.4220 - val_loss: 11.4030 - val_mae: 2.5419\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.7030 - mae: 1.3931 - val_loss: 11.4088 - val_mae: 2.5471\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5866 - mae: 1.3522 - val_loss: 11.2537 - val_mae: 2.5420\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6065 - mae: 1.3479 - val_loss: 11.3146 - val_mae: 2.5197\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.6775 - mae: 1.3838 - val_loss: 11.7082 - val_mae: 2.5898\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6009 - mae: 1.3567 - val_loss: 11.5971 - val_mae: 2.5417\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6791 - mae: 1.3661 - val_loss: 11.3383 - val_mae: 2.5346\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3956 - mae: 1.3245 - val_loss: 11.6270 - val_mae: 2.5473\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4520 - mae: 1.3130 - val_loss: 11.4377 - val_mae: 2.5424\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5139 - mae: 1.3592 - val_loss: 11.6177 - val_mae: 2.5865\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.4926 - mae: 1.3633 - val_loss: 11.4389 - val_mae: 2.5414\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.5351 - mae: 1.3827 - val_loss: 11.9749 - val_mae: 2.5847\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.5972 - mae: 1.3606 - val_loss: 11.5302 - val_mae: 2.5574\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.2300 - mae: 1.2832 - val_loss: 11.7687 - val_mae: 2.5706\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.2147 - mae: 1.2835 - val_loss: 11.4912 - val_mae: 2.5576\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.1683 - mae: 1.2563 - val_loss: 11.7980 - val_mae: 2.5490\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2016 - mae: 1.2782 - val_loss: 11.4904 - val_mae: 2.5629\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0417 - mae: 1.2414 - val_loss: 11.7570 - val_mae: 2.5569\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0792 - mae: 1.2555 - val_loss: 11.5134 - val_mae: 2.5688\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1707 - mae: 1.2541 - val_loss: 11.7899 - val_mae: 2.5546\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2099 - mae: 1.2995 - val_loss: 11.4626 - val_mae: 2.5754\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4411 - mae: 1.3230 - val_loss: 11.8103 - val_mae: 2.5707\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.2887 - mae: 1.3158 - val_loss: 11.6021 - val_mae: 2.5500\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.4358 - mae: 1.3276 - val_loss: 11.6365 - val_mae: 2.5885\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9787 - mae: 1.2508 - val_loss: 12.0189 - val_mae: 2.5725\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9162 - mae: 1.2251 - val_loss: 11.7365 - val_mae: 2.5909\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8042 - mae: 1.1932 - val_loss: 11.7228 - val_mae: 2.5605\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8387 - mae: 1.2014 - val_loss: 11.6156 - val_mae: 2.5793\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.8976 - mae: 1.2104 - val_loss: 11.6998 - val_mae: 2.5750\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9407 - mae: 1.2176 - val_loss: 11.7678 - val_mae: 2.5606\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.8173 - mae: 1.2057 - val_loss: 11.8692 - val_mae: 2.6059\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8032 - mae: 1.1967 - val_loss: 11.7055 - val_mae: 2.5882\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7573 - mae: 1.1920 - val_loss: 11.9077 - val_mae: 2.5923\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7814 - mae: 1.1982 - val_loss: 11.9625 - val_mae: 2.5878\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7032 - mae: 1.1885 - val_loss: 12.0557 - val_mae: 2.6282\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9435 - mae: 1.2108 - val_loss: 12.4103 - val_mae: 2.6523\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9523 - mae: 1.2281 - val_loss: 12.1020 - val_mae: 2.5842\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7251 - mae: 1.2021 - val_loss: 11.8699 - val_mae: 2.6006\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7119 - mae: 1.1692 - val_loss: 12.1127 - val_mae: 2.5853\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9703 - mae: 1.2180 - val_loss: 11.8402 - val_mae: 2.5974\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6796 - mae: 1.2038 - val_loss: 11.8778 - val_mae: 2.5964\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5360 - mae: 1.1258 - val_loss: 11.9748 - val_mae: 2.6007\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4639 - mae: 1.1330 - val_loss: 12.3717 - val_mae: 2.6266\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5461 - mae: 1.1585 - val_loss: 11.9300 - val_mae: 2.6297\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.6379 - mae: 1.1544 - val_loss: 12.2038 - val_mae: 2.6000\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5855 - mae: 1.1484 - val_loss: 11.7233 - val_mae: 2.5928\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4305 - mae: 1.1082 - val_loss: 11.8798 - val_mae: 2.5854\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.4167 - mae: 1.1135 - val_loss: 12.4226 - val_mae: 2.6044\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4754 - mae: 1.1087 - val_loss: 11.9465 - val_mae: 2.6102\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.5986 - mae: 1.1920 - val_loss: 12.4586 - val_mae: 2.6416\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6073 - mae: 1.1709 - val_loss: 12.2981 - val_mae: 2.6144\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6394 - mae: 1.1548 - val_loss: 12.1560 - val_mae: 2.5902\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3601 - mae: 1.1206 - val_loss: 12.0226 - val_mae: 2.6320\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4172 - mae: 1.0961 - val_loss: 12.3573 - val_mae: 2.6098\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.2506 - mae: 1.0789 - val_loss: 12.1775 - val_mae: 2.6264\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.3835 - mae: 1.0979 - val_loss: 12.2064 - val_mae: 2.6305\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1941 - mae: 1.0587 - val_loss: 12.5665 - val_mae: 2.6177\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.2825 - mae: 1.0713 - val_loss: 12.1015 - val_mae: 2.6412\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2169 - mae: 1.0733 - val_loss: 12.8837 - val_mae: 2.6420\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2236 - mae: 1.0670 - val_loss: 12.6060 - val_mae: 2.6458\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1651 - mae: 1.0462 - val_loss: 12.5763 - val_mae: 2.6268\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1611 - mae: 1.0337 - val_loss: 12.5190 - val_mae: 2.6306\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1357 - mae: 1.0567 - val_loss: 12.2081 - val_mae: 2.6521\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1447 - mae: 1.0406 - val_loss: 12.4605 - val_mae: 2.6321\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1865 - mae: 1.0618 - val_loss: 12.0907 - val_mae: 2.6561\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.4624 - mae: 1.1149 - val_loss: 13.0771 - val_mae: 2.6629\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1449 - mae: 1.0591 - val_loss: 12.1788 - val_mae: 2.6535\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0170 - mae: 0.9984 - val_loss: 12.7039 - val_mae: 2.6313\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.2064 - mae: 1.0513 - val_loss: 12.3477 - val_mae: 2.6266\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6990 - mae: 1.1816 - val_loss: 12.4941 - val_mae: 2.7305\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4114 - mae: 1.1431 - val_loss: 13.5255 - val_mae: 2.6709\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.2257 - mae: 1.1048 - val_loss: 12.3987 - val_mae: 2.6956\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1372 - mae: 1.0613 - val_loss: 13.4851 - val_mae: 2.6775\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9490 - mae: 1.0177 - val_loss: 12.2306 - val_mae: 2.6649\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9686 - mae: 1.0043 - val_loss: 13.3902 - val_mae: 2.6702\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9433 - mae: 0.9891 - val_loss: 12.5914 - val_mae: 2.6749\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9138 - mae: 0.9891 - val_loss: 13.0899 - val_mae: 2.6715\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.8204 - mae: 0.9499 - val_loss: 12.3846 - val_mae: 2.6590\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8655 - mae: 0.9585 - val_loss: 12.7419 - val_mae: 2.6765\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.8037 - mae: 0.9418 - val_loss: 12.6550 - val_mae: 2.6456\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9558 - mae: 1.0204 - val_loss: 12.9395 - val_mae: 2.6978\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9666 - mae: 0.9973 - val_loss: 12.7261 - val_mae: 2.6678\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0084 - mae: 1.0085 - val_loss: 12.7746 - val_mae: 2.6477\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.8460 - mae: 1.0051 - val_loss: 12.8792 - val_mae: 2.7257\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1188 - mae: 1.0664 - val_loss: 13.8958 - val_mae: 2.6732\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1362 - mae: 1.0572 - val_loss: 12.5132 - val_mae: 2.6786\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9436 - mae: 1.0308 - val_loss: 13.0343 - val_mae: 2.6582\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.9463 - mae: 1.0015 - val_loss: 13.1971 - val_mae: 2.6594\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9853 - mae: 0.9814 - val_loss: 12.6421 - val_mae: 2.7170\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9787 - mae: 0.9956 - val_loss: 13.7855 - val_mae: 2.6748\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.1170 - mae: 1.0646 - val_loss: 12.2907 - val_mae: 2.6724\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0644 - mae: 1.0781 - val_loss: 12.9731 - val_mae: 2.6914\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.9354 - mae: 1.0350 - val_loss: 13.1503 - val_mae: 2.6553\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8001 - mae: 0.9559 - val_loss: 12.5544 - val_mae: 2.6632\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6377 - mae: 0.9023 - val_loss: 13.3340 - val_mae: 2.6878\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6139 - mae: 0.8986 - val_loss: 12.4756 - val_mae: 2.6539\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6020 - mae: 0.8820 - val_loss: 13.3967 - val_mae: 2.6884\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7931 - mae: 0.9623 - val_loss: 12.9172 - val_mae: 2.7390\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7082 - mae: 0.9185 - val_loss: 12.5954 - val_mae: 2.6377\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6948 - mae: 0.9008 - val_loss: 13.2241 - val_mae: 2.6520\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6209 - mae: 0.9078 - val_loss: 13.1666 - val_mae: 2.7513\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7420 - mae: 0.9447 - val_loss: 13.9996 - val_mae: 2.7017\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6834 - mae: 0.8995 - val_loss: 12.6797 - val_mae: 2.6634\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5536 - mae: 0.8889 - val_loss: 13.0508 - val_mae: 2.6445\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4680 - mae: 0.8646 - val_loss: 13.2390 - val_mae: 2.7391\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5951 - mae: 0.9046 - val_loss: 12.8322 - val_mae: 2.6326\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5074 - mae: 0.8571 - val_loss: 13.2160 - val_mae: 2.6642\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4701 - mae: 0.8443 - val_loss: 13.1485 - val_mae: 2.6947\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5048 - mae: 0.8630 - val_loss: 13.2013 - val_mae: 2.6586\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.6117 - mae: 0.8877 - val_loss: 12.8170 - val_mae: 2.6437\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4436 - mae: 0.8231 - val_loss: 12.9653 - val_mae: 2.6643\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4594 - mae: 0.8472 - val_loss: 13.4091 - val_mae: 2.6565\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5919 - mae: 0.9207 - val_loss: 13.1561 - val_mae: 2.6764\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4071 - mae: 0.8389 - val_loss: 13.4577 - val_mae: 2.7066\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5235 - mae: 0.8408 - val_loss: 12.6132 - val_mae: 2.6598\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.5318 - mae: 0.8714 - val_loss: 12.6729 - val_mae: 2.6722\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6856 - mae: 0.9660 - val_loss: 14.1307 - val_mae: 2.7488\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5724 - mae: 0.9122 - val_loss: 13.1717 - val_mae: 2.6860\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4676 - mae: 0.8288 - val_loss: 12.6684 - val_mae: 2.6709\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3853 - mae: 0.8187 - val_loss: 13.5099 - val_mae: 2.6767\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4034 - mae: 0.8803 - val_loss: 13.6493 - val_mae: 2.8002\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5557 - mae: 0.9046 - val_loss: 13.4567 - val_mae: 2.6820\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3453 - mae: 0.8094 - val_loss: 12.9847 - val_mae: 2.6496\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2981 - mae: 0.7908 - val_loss: 13.3937 - val_mae: 2.6867\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3072 - mae: 0.8081 - val_loss: 13.0087 - val_mae: 2.6937\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.2824 - mae: 0.7963 - val_loss: 13.6347 - val_mae: 2.6836\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4248 - mae: 0.8099 - val_loss: 13.1287 - val_mae: 2.7266\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3084 - mae: 0.8147 - val_loss: 13.6724 - val_mae: 2.7045\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2616 - mae: 0.7809 - val_loss: 13.7049 - val_mae: 2.7065\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2619 - mae: 0.7858 - val_loss: 13.0175 - val_mae: 2.6736\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3436 - mae: 0.8063 - val_loss: 12.9549 - val_mae: 2.6821\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1813 - mae: 0.7498 - val_loss: 13.3278 - val_mae: 2.6675\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1725 - mae: 0.7346 - val_loss: 13.1535 - val_mae: 2.6935\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1464 - mae: 0.7317 - val_loss: 13.3378 - val_mae: 2.6661\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1943 - mae: 0.7683 - val_loss: 13.1061 - val_mae: 2.6804\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2679 - mae: 0.7661 - val_loss: 13.4258 - val_mae: 2.7079\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.1438 - mae: 0.7146 - val_loss: 13.6954 - val_mae: 2.7217\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1699 - mae: 0.7378 - val_loss: 12.9155 - val_mae: 2.6940\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.4019 - mae: 0.8568 - val_loss: 14.5093 - val_mae: 2.7368\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2299 - mae: 0.7622 - val_loss: 13.3524 - val_mae: 2.6794\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2108 - mae: 0.7599 - val_loss: 13.3245 - val_mae: 2.7284\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2022 - mae: 0.7577 - val_loss: 13.6419 - val_mae: 2.7219\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0889 - mae: 0.7230 - val_loss: 13.5830 - val_mae: 2.6943\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1082 - mae: 0.7122 - val_loss: 13.3256 - val_mae: 2.6991\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0757 - mae: 0.6903 - val_loss: 13.6693 - val_mae: 2.7197\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0877 - mae: 0.7091 - val_loss: 13.3887 - val_mae: 2.6782\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0690 - mae: 0.6974 - val_loss: 13.4401 - val_mae: 2.6751\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1331 - mae: 0.7141 - val_loss: 13.3453 - val_mae: 2.6821\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0856 - mae: 0.7090 - val_loss: 13.5457 - val_mae: 2.6762\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1203 - mae: 0.7449 - val_loss: 13.5017 - val_mae: 2.7194\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0397 - mae: 0.7033 - val_loss: 13.7356 - val_mae: 2.7296\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0517 - mae: 0.6716 - val_loss: 13.4098 - val_mae: 2.6914\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0319 - mae: 0.6684 - val_loss: 13.5678 - val_mae: 2.6782\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.0504 - mae: 0.6936 - val_loss: 13.7304 - val_mae: 2.7337\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1353 - mae: 0.7288 - val_loss: 13.6318 - val_mae: 2.7879\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.3848 - mae: 0.8690 - val_loss: 14.3538 - val_mae: 2.7473\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1898 - mae: 0.7786 - val_loss: 13.8241 - val_mae: 2.7299\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1243 - mae: 0.7450 - val_loss: 13.4932 - val_mae: 2.7474\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1058 - mae: 0.7045 - val_loss: 13.3135 - val_mae: 2.6774\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9670 - mae: 0.6604 - val_loss: 13.3808 - val_mae: 2.6919\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9496 - mae: 0.6504 - val_loss: 13.5963 - val_mae: 2.6914\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9630 - mae: 0.6506 - val_loss: 13.7730 - val_mae: 2.7045\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9127 - mae: 0.6357 - val_loss: 13.0603 - val_mae: 2.7049\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0082 - mae: 0.6950 - val_loss: 13.6399 - val_mae: 2.7281\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9381 - mae: 0.6529 - val_loss: 13.4985 - val_mae: 2.7140\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9377 - mae: 0.6333 - val_loss: 13.5052 - val_mae: 2.7025\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9588 - mae: 0.6421 - val_loss: 13.7253 - val_mae: 2.6942\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9661 - mae: 0.6864 - val_loss: 14.0848 - val_mae: 2.7202\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9485 - mae: 0.6559 - val_loss: 13.3912 - val_mae: 2.7321\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9714 - mae: 0.6718 - val_loss: 13.7107 - val_mae: 2.7697\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0504 - mae: 0.6862 - val_loss: 13.1508 - val_mae: 2.6934\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9465 - mae: 0.6545 - val_loss: 13.7761 - val_mae: 2.7057\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9354 - mae: 0.6575 - val_loss: 14.0259 - val_mae: 2.7987\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9343 - mae: 0.6719 - val_loss: 13.3662 - val_mae: 2.6966\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9205 - mae: 0.6413 - val_loss: 13.3768 - val_mae: 2.6537\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8335 - mae: 0.6118 - val_loss: 13.4692 - val_mae: 2.7248\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8418 - mae: 0.6131 - val_loss: 13.3043 - val_mae: 2.6815\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8890 - mae: 0.6485 - val_loss: 13.2715 - val_mae: 2.6905\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9296 - mae: 0.6499 - val_loss: 14.1247 - val_mae: 2.7824\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9190 - mae: 0.6636 - val_loss: 13.2357 - val_mae: 2.6715\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0473 - mae: 0.6872 - val_loss: 13.4867 - val_mae: 2.6674\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9759 - mae: 0.6714 - val_loss: 13.6575 - val_mae: 2.6880\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.9699 - mae: 0.6994 - val_loss: 13.9243 - val_mae: 2.7697\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8701 - mae: 0.6268 - val_loss: 13.6925 - val_mae: 2.7256\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7935 - mae: 0.5738 - val_loss: 13.4171 - val_mae: 2.6790\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7788 - mae: 0.5780 - val_loss: 13.3698 - val_mae: 2.6899\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8085 - mae: 0.5835 - val_loss: 13.7207 - val_mae: 2.7265\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8568 - mae: 0.6240 - val_loss: 13.6569 - val_mae: 2.6982\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8075 - mae: 0.6059 - val_loss: 13.7058 - val_mae: 2.7060\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9408 - mae: 0.6368 - val_loss: 13.0395 - val_mae: 2.7000\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0217 - mae: 0.7261 - val_loss: 14.4787 - val_mae: 2.7829\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 18.2926 - mae: 2.8895\n",
            "Epoch 1/300\n",
            "9/9 [==============================] - 1s 21ms/step - loss: 629.1266 - mae: 23.1462 - val_loss: 484.6389 - val_mae: 20.3672\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 600.3254 - mae: 22.4866 - val_loss: 459.7030 - val_mae: 19.7066\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 566.6193 - mae: 21.7133 - val_loss: 421.4824 - val_mae: 18.6736\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 510.1393 - mae: 20.3389 - val_loss: 356.0284 - val_mae: 16.8058\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 414.6617 - mae: 18.0058 - val_loss: 254.0085 - val_mae: 13.6475\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 276.6647 - mae: 14.2378 - val_loss: 138.8227 - val_mae: 9.6668\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 135.0790 - mae: 9.6995 - val_loss: 77.3453 - val_mae: 7.1146\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 70.8671 - mae: 6.6152 - val_loss: 77.2361 - val_mae: 6.8205\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 58.9830 - mae: 5.9952 - val_loss: 49.5342 - val_mae: 5.2957\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 36.7927 - mae: 4.6947 - val_loss: 35.6541 - val_mae: 4.3766\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 29.2208 - mae: 4.1231 - val_loss: 29.6423 - val_mae: 3.8926\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 23.9212 - mae: 3.7338 - val_loss: 27.8252 - val_mae: 3.7912\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 21.4007 - mae: 3.5998 - val_loss: 25.6186 - val_mae: 3.6289\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 19.2452 - mae: 3.4037 - val_loss: 23.8278 - val_mae: 3.4810\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 17.7685 - mae: 3.2372 - val_loss: 22.3988 - val_mae: 3.3370\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 16.7851 - mae: 3.1321 - val_loss: 21.5471 - val_mae: 3.2527\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.7215 - mae: 3.0147 - val_loss: 20.9278 - val_mae: 3.1888\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 15.0103 - mae: 2.9178 - val_loss: 20.3695 - val_mae: 3.1231\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 14.4565 - mae: 2.9136 - val_loss: 20.5548 - val_mae: 3.1680\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 13.8083 - mae: 2.8488 - val_loss: 20.0908 - val_mae: 3.0799\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 13.2194 - mae: 2.7402 - val_loss: 19.2621 - val_mae: 2.9686\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 12.7045 - mae: 2.7194 - val_loss: 19.5861 - val_mae: 2.9959\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 12.2515 - mae: 2.6641 - val_loss: 18.8079 - val_mae: 2.8902\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.6356 - mae: 2.5697 - val_loss: 18.3404 - val_mae: 2.8221\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 11.2772 - mae: 2.5429 - val_loss: 18.3941 - val_mae: 2.8340\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 10.8805 - mae: 2.4999 - val_loss: 17.7405 - val_mae: 2.7498\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 10.6426 - mae: 2.4368 - val_loss: 17.3829 - val_mae: 2.7112\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 10.2038 - mae: 2.4188 - val_loss: 18.4131 - val_mae: 2.7970\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.9015 - mae: 2.3779 - val_loss: 17.7792 - val_mae: 2.7146\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 9.7937 - mae: 2.3423 - val_loss: 17.1890 - val_mae: 2.6606\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.4846 - mae: 2.3439 - val_loss: 17.9850 - val_mae: 2.7327\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 9.2626 - mae: 2.3183 - val_loss: 17.5392 - val_mae: 2.6711\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 9.0147 - mae: 2.2736 - val_loss: 17.3721 - val_mae: 2.6454\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 8.6697 - mae: 2.2175 - val_loss: 16.9418 - val_mae: 2.6151\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 8.4810 - mae: 2.1829 - val_loss: 17.0356 - val_mae: 2.6331\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 8.3153 - mae: 2.1535 - val_loss: 16.7927 - val_mae: 2.6077\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 8.0898 - mae: 2.1400 - val_loss: 16.9417 - val_mae: 2.6249\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.8912 - mae: 2.1070 - val_loss: 16.4772 - val_mae: 2.5582\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.8318 - mae: 2.0810 - val_loss: 16.7114 - val_mae: 2.5863\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.6747 - mae: 2.0738 - val_loss: 16.3576 - val_mae: 2.5542\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.5595 - mae: 2.0537 - val_loss: 16.6632 - val_mae: 2.5946\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 7.3642 - mae: 2.0342 - val_loss: 16.2253 - val_mae: 2.5425\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 7.3103 - mae: 1.9986 - val_loss: 15.9863 - val_mae: 2.5259\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 7.1300 - mae: 1.9880 - val_loss: 16.1111 - val_mae: 2.5676\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.9876 - mae: 1.9702 - val_loss: 15.8866 - val_mae: 2.5327\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.8589 - mae: 1.9469 - val_loss: 15.8873 - val_mae: 2.5401\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.7666 - mae: 1.9296 - val_loss: 15.9963 - val_mae: 2.5548\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.7322 - mae: 1.9303 - val_loss: 15.9233 - val_mae: 2.5452\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5841 - mae: 1.9081 - val_loss: 15.7171 - val_mae: 2.5222\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.6296 - mae: 1.9108 - val_loss: 15.6970 - val_mae: 2.5267\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.5671 - mae: 1.9191 - val_loss: 15.8810 - val_mae: 2.5415\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 6.5249 - mae: 1.9185 - val_loss: 15.6636 - val_mae: 2.5299\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.3274 - mae: 1.8629 - val_loss: 15.4511 - val_mae: 2.5115\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 6.2021 - mae: 1.8411 - val_loss: 15.5369 - val_mae: 2.5199\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 6.1285 - mae: 1.8406 - val_loss: 15.4298 - val_mae: 2.5268\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 6.1205 - mae: 1.8495 - val_loss: 15.4738 - val_mae: 2.5262\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9395 - mae: 1.7919 - val_loss: 15.2611 - val_mae: 2.5047\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.9171 - mae: 1.7937 - val_loss: 15.4446 - val_mae: 2.5214\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.8835 - mae: 1.7973 - val_loss: 15.4145 - val_mae: 2.5136\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.7844 - mae: 1.7759 - val_loss: 15.3772 - val_mae: 2.5201\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.9413 - mae: 1.7809 - val_loss: 15.0302 - val_mae: 2.4886\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.6800 - mae: 1.7742 - val_loss: 15.3616 - val_mae: 2.5398\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.5772 - mae: 1.7320 - val_loss: 14.9545 - val_mae: 2.4885\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.7102 - mae: 1.7654 - val_loss: 15.4030 - val_mae: 2.5275\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3893 - mae: 1.7071 - val_loss: 14.8515 - val_mae: 2.4725\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.3939 - mae: 1.7068 - val_loss: 14.9053 - val_mae: 2.4881\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3263 - mae: 1.7006 - val_loss: 15.2849 - val_mae: 2.5197\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.3327 - mae: 1.7124 - val_loss: 15.1611 - val_mae: 2.5168\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 5.3003 - mae: 1.7080 - val_loss: 15.0208 - val_mae: 2.5019\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.2447 - mae: 1.6826 - val_loss: 15.2444 - val_mae: 2.5133\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 5.0886 - mae: 1.6596 - val_loss: 14.6531 - val_mae: 2.4769\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 5.0721 - mae: 1.6517 - val_loss: 14.9533 - val_mae: 2.5271\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0803 - mae: 1.6709 - val_loss: 15.0151 - val_mae: 2.5131\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.9563 - mae: 1.6343 - val_loss: 14.6093 - val_mae: 2.4800\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.9858 - mae: 1.6617 - val_loss: 14.7684 - val_mae: 2.5009\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.1784 - mae: 1.6809 - val_loss: 14.2895 - val_mae: 2.4585\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 5.0692 - mae: 1.6737 - val_loss: 14.4453 - val_mae: 2.4840\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7248 - mae: 1.5990 - val_loss: 13.9502 - val_mae: 2.4255\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.7340 - mae: 1.5998 - val_loss: 14.2290 - val_mae: 2.4586\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.6522 - mae: 1.5887 - val_loss: 14.0717 - val_mae: 2.4379\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6288 - mae: 1.5773 - val_loss: 14.3373 - val_mae: 2.4710\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.5506 - mae: 1.5753 - val_loss: 13.7798 - val_mae: 2.4193\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4977 - mae: 1.5698 - val_loss: 14.0032 - val_mae: 2.4641\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4988 - mae: 1.5797 - val_loss: 13.9864 - val_mae: 2.4531\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6629 - mae: 1.5917 - val_loss: 14.3282 - val_mae: 2.4648\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.6238 - mae: 1.6003 - val_loss: 14.0246 - val_mae: 2.4401\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.4332 - mae: 1.5863 - val_loss: 14.1883 - val_mae: 2.4623\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2449 - mae: 1.5300 - val_loss: 13.7221 - val_mae: 2.4193\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.4568 - mae: 1.5681 - val_loss: 14.2147 - val_mae: 2.4780\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.2308 - mae: 1.5371 - val_loss: 13.3794 - val_mae: 2.3794\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.2615 - mae: 1.5481 - val_loss: 13.8566 - val_mae: 2.4412\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 4.3560 - mae: 1.5524 - val_loss: 13.4409 - val_mae: 2.4039\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 4.5404 - mae: 1.5910 - val_loss: 13.7599 - val_mae: 2.4343\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.2118 - mae: 1.5423 - val_loss: 13.3404 - val_mae: 2.3841\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 4.0696 - mae: 1.5078 - val_loss: 13.5528 - val_mae: 2.4260\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.9186 - mae: 1.4741 - val_loss: 13.1447 - val_mae: 2.3934\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 4.0024 - mae: 1.4727 - val_loss: 13.5248 - val_mae: 2.4406\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.8968 - mae: 1.4759 - val_loss: 12.9374 - val_mae: 2.3597\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8355 - mae: 1.4585 - val_loss: 13.0185 - val_mae: 2.3798\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.8548 - mae: 1.4663 - val_loss: 13.1450 - val_mae: 2.3884\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.7792 - mae: 1.4446 - val_loss: 12.8811 - val_mae: 2.3520\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.9338 - mae: 1.4785 - val_loss: 13.3193 - val_mae: 2.4183\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.9237 - mae: 1.4898 - val_loss: 12.6224 - val_mae: 2.3271\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.6364 - mae: 1.4174 - val_loss: 12.8026 - val_mae: 2.3608\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.6742 - mae: 1.4322 - val_loss: 12.8358 - val_mae: 2.3626\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.5106 - mae: 1.3986 - val_loss: 12.3828 - val_mae: 2.3198\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.5386 - mae: 1.3965 - val_loss: 12.4447 - val_mae: 2.3372\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4441 - mae: 1.3830 - val_loss: 12.4322 - val_mae: 2.3386\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4162 - mae: 1.3726 - val_loss: 12.3083 - val_mae: 2.3185\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4611 - mae: 1.3713 - val_loss: 12.7084 - val_mae: 2.3677\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3705 - mae: 1.3790 - val_loss: 12.3312 - val_mae: 2.3193\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.4626 - mae: 1.4000 - val_loss: 12.6290 - val_mae: 2.3406\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.3027 - mae: 1.3526 - val_loss: 12.3772 - val_mae: 2.3189\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2861 - mae: 1.3556 - val_loss: 12.3855 - val_mae: 2.3346\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.4390 - mae: 1.4086 - val_loss: 12.0993 - val_mae: 2.3145\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.4697 - mae: 1.4149 - val_loss: 12.8430 - val_mae: 2.3971\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 3.3006 - mae: 1.3746 - val_loss: 11.9905 - val_mae: 2.2735\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.2303 - mae: 1.3687 - val_loss: 12.4053 - val_mae: 2.3356\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0838 - mae: 1.3033 - val_loss: 12.1272 - val_mae: 2.3016\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 3.0200 - mae: 1.3004 - val_loss: 12.2034 - val_mae: 2.3208\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.1625 - mae: 1.3202 - val_loss: 11.8444 - val_mae: 2.2786\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 3.0202 - mae: 1.2880 - val_loss: 12.1378 - val_mae: 2.3083\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.9822 - mae: 1.2957 - val_loss: 12.2054 - val_mae: 2.3175\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9643 - mae: 1.2823 - val_loss: 12.2401 - val_mae: 2.3225\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.9690 - mae: 1.3031 - val_loss: 12.0978 - val_mae: 2.3162\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8619 - mae: 1.2688 - val_loss: 12.1256 - val_mae: 2.3004\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.8479 - mae: 1.2711 - val_loss: 11.8279 - val_mae: 2.2858\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.8863 - mae: 1.2678 - val_loss: 12.2030 - val_mae: 2.3266\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7670 - mae: 1.2510 - val_loss: 11.8728 - val_mae: 2.2873\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7794 - mae: 1.2521 - val_loss: 11.6597 - val_mae: 2.2733\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6962 - mae: 1.2400 - val_loss: 12.0466 - val_mae: 2.3076\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.6608 - mae: 1.2195 - val_loss: 11.7198 - val_mae: 2.2819\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.7160 - mae: 1.2402 - val_loss: 11.7738 - val_mae: 2.2902\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.6083 - mae: 1.2147 - val_loss: 11.7020 - val_mae: 2.2823\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5841 - mae: 1.2000 - val_loss: 11.4855 - val_mae: 2.2394\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6020 - mae: 1.2105 - val_loss: 11.8003 - val_mae: 2.2998\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.5532 - mae: 1.1870 - val_loss: 11.8474 - val_mae: 2.3059\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.5365 - mae: 1.2034 - val_loss: 11.4403 - val_mae: 2.2539\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7043 - mae: 1.2344 - val_loss: 12.6119 - val_mae: 2.4211\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 2.7455 - mae: 1.2788 - val_loss: 11.3987 - val_mae: 2.2295\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.6080 - mae: 1.2328 - val_loss: 11.7560 - val_mae: 2.3297\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.7192 - mae: 1.2801 - val_loss: 11.7800 - val_mae: 2.3096\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.7960 - mae: 1.2835 - val_loss: 11.4462 - val_mae: 2.3022\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.4691 - mae: 1.1612 - val_loss: 11.6321 - val_mae: 2.2975\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.3574 - mae: 1.1176 - val_loss: 11.6446 - val_mae: 2.3070\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.4502 - mae: 1.1807 - val_loss: 11.9232 - val_mae: 2.3262\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.3362 - mae: 1.1372 - val_loss: 11.6884 - val_mae: 2.3064\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2252 - mae: 1.1131 - val_loss: 11.3888 - val_mae: 2.2447\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2605 - mae: 1.1072 - val_loss: 12.1341 - val_mae: 2.3666\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2204 - mae: 1.1210 - val_loss: 11.4800 - val_mae: 2.2927\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.2277 - mae: 1.1152 - val_loss: 11.8142 - val_mae: 2.3313\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1820 - mae: 1.0993 - val_loss: 11.4747 - val_mae: 2.2795\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2037 - mae: 1.1160 - val_loss: 11.2175 - val_mae: 2.2529\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.1931 - mae: 1.1162 - val_loss: 11.5333 - val_mae: 2.3115\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.1118 - mae: 1.0751 - val_loss: 11.3920 - val_mae: 2.2942\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0080 - mae: 1.0448 - val_loss: 11.1950 - val_mae: 2.2551\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 2.0929 - mae: 1.0707 - val_loss: 11.4634 - val_mae: 2.3039\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.1239 - mae: 1.0827 - val_loss: 11.8434 - val_mae: 2.3522\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0610 - mae: 1.0679 - val_loss: 11.4296 - val_mae: 2.2958\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9532 - mae: 1.0394 - val_loss: 11.0520 - val_mae: 2.2439\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9061 - mae: 1.0332 - val_loss: 11.7503 - val_mae: 2.3519\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 2.0021 - mae: 1.0588 - val_loss: 10.8280 - val_mae: 2.1761\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.3161 - mae: 1.1875 - val_loss: 12.0844 - val_mae: 2.3903\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9965 - mae: 1.0610 - val_loss: 11.5406 - val_mae: 2.3077\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0044 - mae: 1.0482 - val_loss: 11.3802 - val_mae: 2.3459\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.0868 - mae: 1.0949 - val_loss: 12.5344 - val_mae: 2.4575\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 2.2729 - mae: 1.1294 - val_loss: 10.9349 - val_mae: 2.2754\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.9388 - mae: 1.0402 - val_loss: 11.7940 - val_mae: 2.3641\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.9717 - mae: 1.0369 - val_loss: 11.4743 - val_mae: 2.3140\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.7570 - mae: 0.9798 - val_loss: 10.7872 - val_mae: 2.1938\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7952 - mae: 0.9895 - val_loss: 11.6758 - val_mae: 2.3391\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.7388 - mae: 0.9805 - val_loss: 11.4417 - val_mae: 2.2973\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.7288 - mae: 0.9619 - val_loss: 11.2234 - val_mae: 2.2666\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6682 - mae: 0.9506 - val_loss: 10.8792 - val_mae: 2.2204\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6915 - mae: 0.9651 - val_loss: 11.3626 - val_mae: 2.3212\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.7093 - mae: 0.9528 - val_loss: 11.1706 - val_mae: 2.2663\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5925 - mae: 0.9218 - val_loss: 10.9076 - val_mae: 2.2319\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5871 - mae: 0.9092 - val_loss: 11.5537 - val_mae: 2.3221\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.6347 - mae: 0.9276 - val_loss: 10.9581 - val_mae: 2.2224\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.6052 - mae: 0.9225 - val_loss: 11.3848 - val_mae: 2.3055\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.6425 - mae: 0.9559 - val_loss: 11.0452 - val_mae: 2.3086\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.8114 - mae: 0.9815 - val_loss: 12.0690 - val_mae: 2.3877\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.7250 - mae: 0.9503 - val_loss: 11.5328 - val_mae: 2.3114\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.6442 - mae: 0.9609 - val_loss: 11.3089 - val_mae: 2.2910\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5702 - mae: 0.9095 - val_loss: 11.4732 - val_mae: 2.2961\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.5829 - mae: 0.9081 - val_loss: 10.9161 - val_mae: 2.2670\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.5240 - mae: 0.9085 - val_loss: 12.1131 - val_mae: 2.3951\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4578 - mae: 0.8719 - val_loss: 11.0572 - val_mae: 2.2408\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4260 - mae: 0.8807 - val_loss: 11.2970 - val_mae: 2.2840\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4480 - mae: 0.8886 - val_loss: 11.2428 - val_mae: 2.3223\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5949 - mae: 0.9223 - val_loss: 11.4630 - val_mae: 2.3073\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.4555 - mae: 0.8988 - val_loss: 11.1823 - val_mae: 2.2832\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4131 - mae: 0.8731 - val_loss: 10.6836 - val_mae: 2.2088\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4708 - mae: 0.8766 - val_loss: 11.6953 - val_mae: 2.3374\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4697 - mae: 0.8761 - val_loss: 11.3217 - val_mae: 2.2973\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4125 - mae: 0.8480 - val_loss: 10.9336 - val_mae: 2.2481\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.4278 - mae: 0.8705 - val_loss: 12.0484 - val_mae: 2.3984\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.3770 - mae: 0.8747 - val_loss: 11.1827 - val_mae: 2.2994\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.3429 - mae: 0.8471 - val_loss: 11.3914 - val_mae: 2.2911\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3914 - mae: 0.8562 - val_loss: 11.2121 - val_mae: 2.2688\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4621 - mae: 0.8956 - val_loss: 11.5986 - val_mae: 2.3334\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3169 - mae: 0.8478 - val_loss: 10.7148 - val_mae: 2.1857\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.4684 - mae: 0.9003 - val_loss: 12.2174 - val_mae: 2.4143\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3616 - mae: 0.8743 - val_loss: 11.2610 - val_mae: 2.2773\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2427 - mae: 0.8171 - val_loss: 10.8370 - val_mae: 2.2203\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.3306 - mae: 0.8531 - val_loss: 11.8210 - val_mae: 2.3546\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2802 - mae: 0.8300 - val_loss: 11.7430 - val_mae: 2.3254\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.2118 - mae: 0.8110 - val_loss: 11.3563 - val_mae: 2.2891\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1880 - mae: 0.7881 - val_loss: 11.0811 - val_mae: 2.2813\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2018 - mae: 0.7811 - val_loss: 11.2231 - val_mae: 2.2753\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1726 - mae: 0.7819 - val_loss: 11.5903 - val_mae: 2.3086\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.2637 - mae: 0.8214 - val_loss: 11.3708 - val_mae: 2.3084\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1475 - mae: 0.7844 - val_loss: 11.4070 - val_mae: 2.2982\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1783 - mae: 0.7939 - val_loss: 12.1086 - val_mae: 2.3896\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 1.2001 - mae: 0.8216 - val_loss: 10.8261 - val_mae: 2.2467\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.1478 - mae: 0.7597 - val_loss: 11.5542 - val_mae: 2.3111\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0850 - mae: 0.7677 - val_loss: 11.5338 - val_mae: 2.3071\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1614 - mae: 0.7934 - val_loss: 11.0206 - val_mae: 2.2542\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1956 - mae: 0.7584 - val_loss: 11.8378 - val_mae: 2.3484\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.1253 - mae: 0.7527 - val_loss: 11.3014 - val_mae: 2.3048\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0646 - mae: 0.7551 - val_loss: 11.4353 - val_mae: 2.2969\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 1.0179 - mae: 0.7166 - val_loss: 11.3744 - val_mae: 2.2909\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0635 - mae: 0.7489 - val_loss: 11.6407 - val_mae: 2.3273\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 1.0327 - mae: 0.7317 - val_loss: 11.9333 - val_mae: 2.3656\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0371 - mae: 0.7385 - val_loss: 11.2363 - val_mae: 2.2672\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1289 - mae: 0.7458 - val_loss: 11.1714 - val_mae: 2.2755\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0692 - mae: 0.7373 - val_loss: 11.6852 - val_mae: 2.3283\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9968 - mae: 0.7087 - val_loss: 11.5786 - val_mae: 2.3295\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9649 - mae: 0.6956 - val_loss: 11.3477 - val_mae: 2.2923\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9560 - mae: 0.6934 - val_loss: 11.4662 - val_mae: 2.3034\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9691 - mae: 0.7025 - val_loss: 11.6900 - val_mae: 2.3481\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9418 - mae: 0.6824 - val_loss: 11.7350 - val_mae: 2.3319\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9314 - mae: 0.6830 - val_loss: 11.3807 - val_mae: 2.2861\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9165 - mae: 0.6828 - val_loss: 12.0884 - val_mae: 2.3733\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9684 - mae: 0.7141 - val_loss: 11.9046 - val_mae: 2.3458\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.0019 - mae: 0.7180 - val_loss: 11.3599 - val_mae: 2.2883\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9278 - mae: 0.6814 - val_loss: 11.3506 - val_mae: 2.2947\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9129 - mae: 0.6893 - val_loss: 11.9571 - val_mae: 2.3607\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9273 - mae: 0.6786 - val_loss: 11.6018 - val_mae: 2.3063\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9176 - mae: 0.6643 - val_loss: 11.4665 - val_mae: 2.3122\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9302 - mae: 0.6905 - val_loss: 11.6686 - val_mae: 2.3240\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.9486 - mae: 0.7086 - val_loss: 11.6872 - val_mae: 2.3287\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.9293 - mae: 0.6921 - val_loss: 11.7298 - val_mae: 2.3225\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8795 - mae: 0.6774 - val_loss: 11.8718 - val_mae: 2.3562\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8971 - mae: 0.6812 - val_loss: 11.4589 - val_mae: 2.2917\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8602 - mae: 0.6459 - val_loss: 11.3087 - val_mae: 2.2712\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.9079 - mae: 0.6828 - val_loss: 11.7125 - val_mae: 2.3181\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8783 - mae: 0.6715 - val_loss: 11.8173 - val_mae: 2.3549\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8427 - mae: 0.6409 - val_loss: 11.6122 - val_mae: 2.3031\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8394 - mae: 0.6540 - val_loss: 12.0513 - val_mae: 2.3700\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8476 - mae: 0.6628 - val_loss: 11.9373 - val_mae: 2.3597\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8247 - mae: 0.6423 - val_loss: 11.4883 - val_mae: 2.3034\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7957 - mae: 0.6305 - val_loss: 11.6327 - val_mae: 2.3308\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8504 - mae: 0.6304 - val_loss: 12.0289 - val_mae: 2.3566\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7943 - mae: 0.6196 - val_loss: 11.7728 - val_mae: 2.3433\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.8320 - mae: 0.6504 - val_loss: 11.7198 - val_mae: 2.3384\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7688 - mae: 0.6202 - val_loss: 11.6693 - val_mae: 2.3074\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7836 - mae: 0.6469 - val_loss: 11.7735 - val_mae: 2.3468\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.8037 - mae: 0.6301 - val_loss: 12.0716 - val_mae: 2.3738\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8377 - mae: 0.6460 - val_loss: 12.2735 - val_mae: 2.3840\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8165 - mae: 0.6350 - val_loss: 11.6893 - val_mae: 2.3280\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7578 - mae: 0.6089 - val_loss: 11.9833 - val_mae: 2.3754\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7794 - mae: 0.6347 - val_loss: 11.8276 - val_mae: 2.3379\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7398 - mae: 0.5976 - val_loss: 11.6998 - val_mae: 2.3225\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7656 - mae: 0.6028 - val_loss: 11.9045 - val_mae: 2.3564\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7288 - mae: 0.5956 - val_loss: 12.3611 - val_mae: 2.4153\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7108 - mae: 0.5886 - val_loss: 11.9534 - val_mae: 2.3596\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7451 - mae: 0.6028 - val_loss: 11.7267 - val_mae: 2.3395\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7473 - mae: 0.6210 - val_loss: 11.7419 - val_mae: 2.3266\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7717 - mae: 0.6167 - val_loss: 12.3985 - val_mae: 2.3973\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8403 - mae: 0.6614 - val_loss: 13.1086 - val_mae: 2.4929\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.8150 - mae: 0.6857 - val_loss: 11.6650 - val_mae: 2.3128\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7747 - mae: 0.6419 - val_loss: 11.8699 - val_mae: 2.3432\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7507 - mae: 0.6168 - val_loss: 12.4441 - val_mae: 2.4213\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7538 - mae: 0.6001 - val_loss: 12.1640 - val_mae: 2.3768\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7051 - mae: 0.6005 - val_loss: 12.0742 - val_mae: 2.3794\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8016 - mae: 0.6558 - val_loss: 11.6216 - val_mae: 2.3196\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7612 - mae: 0.6085 - val_loss: 12.0042 - val_mae: 2.3638\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7142 - mae: 0.6108 - val_loss: 12.3632 - val_mae: 2.4003\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.7305 - mae: 0.6246 - val_loss: 12.0098 - val_mae: 2.3836\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7570 - mae: 0.6267 - val_loss: 11.8370 - val_mae: 2.3387\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7146 - mae: 0.6039 - val_loss: 11.6734 - val_mae: 2.3336\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7647 - mae: 0.6346 - val_loss: 12.0440 - val_mae: 2.4022\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7339 - mae: 0.5963 - val_loss: 13.1083 - val_mae: 2.4925\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.8320 - mae: 0.6700 - val_loss: 12.5848 - val_mae: 2.4567\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7102 - mae: 0.6110 - val_loss: 11.8981 - val_mae: 2.3709\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7041 - mae: 0.6097 - val_loss: 11.5975 - val_mae: 2.3294\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7150 - mae: 0.6044 - val_loss: 12.3032 - val_mae: 2.4063\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.7419 - mae: 0.6109 - val_loss: 12.1371 - val_mae: 2.3889\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6512 - mae: 0.5670 - val_loss: 12.6472 - val_mae: 2.4552\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6441 - mae: 0.5656 - val_loss: 12.0293 - val_mae: 2.3833\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6251 - mae: 0.5373 - val_loss: 12.1841 - val_mae: 2.3999\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.6317 - mae: 0.5409 - val_loss: 12.1939 - val_mae: 2.3912\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.6224 - mae: 0.5440 - val_loss: 12.5688 - val_mae: 2.4435\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.6841 - mae: 0.6118 - val_loss: 12.2616 - val_mae: 2.4095\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6080 - mae: 0.5517 - val_loss: 12.5761 - val_mae: 2.4459\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6420 - mae: 0.5495 - val_loss: 12.7300 - val_mae: 2.4567\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7296 - mae: 0.6080 - val_loss: 12.7681 - val_mae: 2.4683\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.8342 - mae: 0.6680 - val_loss: 12.0930 - val_mae: 2.4215\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.7652 - mae: 0.6336 - val_loss: 12.1162 - val_mae: 2.4122\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 21.3205 - mae: 2.8735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJB6bWP_Y80O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44333302-1dcf-4456-d2b2-1e3bb93984e0"
      },
      "source": [
        "print(mae_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.839651346206665, 2.8895013332366943, 2.873504638671875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjwxuiq4cITg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7ac1ea5-c6ec-4c31-d895-d48ce45d86b0"
      },
      "source": [
        "print(np.mean(mae_list)) #각 fold에서 모델은 평균적으로 실제 주택가격과 2860달러정도 오차가 존재"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8675524393717446\n"
          ]
        }
      ]
    }
  ]
}